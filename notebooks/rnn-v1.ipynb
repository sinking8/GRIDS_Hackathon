{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-17T05:08:16.647351Z","iopub.execute_input":"2023-09-17T05:08:16.647841Z","iopub.status.idle":"2023-09-17T05:08:17.153166Z","shell.execute_reply.started":"2023-09-17T05:08:16.647804Z","shell.execute_reply":"2023-09-17T05:08:17.151550Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/audio-based-violence-detection-dataset/VSD.xlsx\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_20.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_043.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_07.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_141.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_122.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_049.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_061.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_162.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_094.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_022.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_021.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_081.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_16.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_142.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_191.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_073.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_04.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_06.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_171.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_18.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_202.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_111.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_011.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_12.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_14.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_101.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_204.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_054.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_077.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_033.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_042.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/noviolence_03.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_095.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_205.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_056.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_016.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_102.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_051.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_05.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_133.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_103.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_02.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_044.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_17.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_017.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_067.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_134.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_055.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_046.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_161.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_025.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_091.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_037.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_152.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_145.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_074.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_041.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_027.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_01.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_014.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_092.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_038.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_121.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_034.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_132.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_063.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_065.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_104.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_023.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_053.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_15.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_045.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_018.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_013.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_075.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_062.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_012.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_192.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_032.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_085.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_153.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_144.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_13.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_028.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_203.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/noviolence_01.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_058.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_182.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_211.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_206.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_084.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_076.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_10.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_026.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_19.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/noviolence_02.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_066.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_052.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_031.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_035.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_151.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_131.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_093.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_024.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_039.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_059.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_083.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_193.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_09.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_072.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_071.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_015.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_112.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_181.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_113.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_03.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_049a.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_143.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_11.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_086.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_201.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_049b.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_047.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_064.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_036.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_057.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_048.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_08.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_21.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/angry_082.wav\n/kaggle/input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD/noviolence_04.wav\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport librosa.display, os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef create_spectrogram(audio_file, image_file):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    y, sr = librosa.load(audio_file)\n    ms = librosa.feature.melspectrogram(y, sr=sr)\n    log_ms = librosa.power_to_db(ms, ref=np.max)\n    librosa.display.specshow(log_ms, sr=sr)\n\n    fig.savefig(image_file)\n    plt.close(fig)\n    \ndef create_pngs_from_wavs(input_path, output_path):\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    dir = os.listdir(input_path)\n\n    for i, file in enumerate(dir):\n        input_file = os.path.join(input_path, file)\n        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n        create_spectrogram(input_file, output_file)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.155277Z","iopub.execute_input":"2023-09-17T05:08:17.155777Z","iopub.status.idle":"2023-09-17T05:08:17.219817Z","shell.execute_reply.started":"2023-09-17T05:08:17.155743Z","shell.execute_reply":"2023-09-17T05:08:17.218430Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.221769Z","iopub.execute_input":"2023-09-17T05:08:17.222418Z","iopub.status.idle":"2023-09-17T05:08:17.227995Z","shell.execute_reply.started":"2023-09-17T05:08:17.222387Z","shell.execute_reply":"2023-09-17T05:08:17.226780Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"print(os.listdir(\"../\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.231932Z","iopub.execute_input":"2023-09-17T05:08:17.232785Z","iopub.status.idle":"2023-09-17T05:08:17.244090Z","shell.execute_reply.started":"2023-09-17T05:08:17.232735Z","shell.execute_reply":"2023-09-17T05:08:17.242571Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['lib', 'input', 'working']\n","output_type":"stream"}]},{"cell_type":"code","source":"metal_excel_dir = \"../input/audio-based-violence-detection-dataset/VSD.xlsx\"","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.246055Z","iopub.execute_input":"2023-09-17T05:08:17.246747Z","iopub.status.idle":"2023-09-17T05:08:17.257853Z","shell.execute_reply.started":"2023-09-17T05:08:17.246702Z","shell.execute_reply":"2023-09-17T05:08:17.256850Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"../input/audio-based-violence-detection-dataset\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.259494Z","iopub.execute_input":"2023-09-17T05:08:17.260412Z","iopub.status.idle":"2023-09-17T05:08:17.274865Z","shell.execute_reply.started":"2023-09-17T05:08:17.260354Z","shell.execute_reply":"2023-09-17T05:08:17.273597Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['audios_VSD', 'VSD.xlsx']\n","output_type":"stream"}]},{"cell_type":"code","source":"metadata = pd.read_excel(metal_excel_dir,sheet_name='read_dataset')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.276590Z","iopub.execute_input":"2023-09-17T05:08:17.277199Z","iopub.status.idle":"2023-09-17T05:08:17.767076Z","shell.execute_reply.started":"2023-09-17T05:08:17.277156Z","shell.execute_reply":"2023-09-17T05:08:17.765486Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"metadata = metadata.drop(metadata[metadata['File_segment_name'] == \"NaN\"].index)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.769863Z","iopub.execute_input":"2023-09-17T05:08:17.770375Z","iopub.status.idle":"2023-09-17T05:08:17.785150Z","shell.execute_reply.started":"2023-09-17T05:08:17.770342Z","shell.execute_reply":"2023-09-17T05:08:17.783788Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"metadata.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.787006Z","iopub.execute_input":"2023-09-17T05:08:17.787362Z","iopub.status.idle":"2023-09-17T05:08:17.803357Z","shell.execute_reply.started":"2023-09-17T05:08:17.787332Z","shell.execute_reply":"2023-09-17T05:08:17.801725Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(341, 5)"},"metadata":{}}]},{"cell_type":"code","source":"print(metadata.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.808796Z","iopub.execute_input":"2023-09-17T05:08:17.809183Z","iopub.status.idle":"2023-09-17T05:08:17.816095Z","shell.execute_reply.started":"2023-09-17T05:08:17.809150Z","shell.execute_reply":"2023-09-17T05:08:17.814641Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(341, 5)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"metadata.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T23:07:29.801963Z","iopub.execute_input":"2023-09-16T23:07:29.802356Z","iopub.status.idle":"2023-09-16T23:07:29.827557Z","shell.execute_reply.started":"2023-09-16T23:07:29.802326Z","shell.execute_reply":"2023-09-16T23:07:29.826564Z"}}},{"cell_type":"code","source":"print(metadata.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.818213Z","iopub.execute_input":"2023-09-17T05:08:17.818739Z","iopub.status.idle":"2023-09-17T05:08:17.840350Z","shell.execute_reply.started":"2023-09-17T05:08:17.818693Z","shell.execute_reply":"2023-09-17T05:08:17.838703Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"  File_segment_name  Duration  Violence_start  Violence_end  Violence_duration\n0         angry_011     117.0            21.0        38.000              17.00\n1         angry_011     117.0            40.0        55.000              15.00\n2         angry_011     117.0            60.0        79.000              19.00\n3         angry_011     117.0            85.0        95.000              10.00\n4         angry_011     117.0           101.0       110.000               9.00\n5         angry_012      32.0             0.0         0.020               0.02\n6         angry_013      72.0             0.0         0.010               0.00\n7         angry_014      50.0             0.0         0.012               0.00\n8         angry_015     162.0            64.0        71.000               7.00\n9         angry_015     162.0            89.0       100.000              11.00\n","output_type":"stream"}]},{"cell_type":"code","source":"violence_dir =\"../violence_data\"\nnon_violence_dir = \"../non_violence_data\"","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.841630Z","iopub.execute_input":"2023-09-17T05:08:17.842011Z","iopub.status.idle":"2023-09-17T05:08:17.848256Z","shell.execute_reply.started":"2023-09-17T05:08:17.841980Z","shell.execute_reply":"2023-09-17T05:08:17.847311Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"os.mkdir(violence_dir)\nos.mkdir(non_violence_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.850104Z","iopub.execute_input":"2023-09-17T05:08:17.850468Z","iopub.status.idle":"2023-09-17T05:08:17.862230Z","shell.execute_reply.started":"2023-09-17T05:08:17.850436Z","shell.execute_reply":"2023-09-17T05:08:17.861195Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip install pydub","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:17.863900Z","iopub.execute_input":"2023-09-17T05:08:17.864253Z","iopub.status.idle":"2023-09-17T05:08:54.541353Z","shell.execute_reply.started":"2023-09-17T05:08:17.864223Z","shell.execute_reply":"2023-09-17T05:08:54.539980Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from pydub import AudioSegment\nimport math\n\nfor record in metadata.values:\n    print(record)\n    t1 = 1000 * record[2]\n    t2 = 1000 * record[3]\n    audio  = AudioSegment.from_wav(os.path.join(\"../input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD\",str(record[0])+\".wav\"))\n    violence_segment = audio[t1:t2]\n    violence_segment.export(os.path.join(violence_dir,record[0]+\".wav\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:08:54.543559Z","iopub.execute_input":"2023-09-17T05:08:54.543961Z","iopub.status.idle":"2023-09-17T05:11:39.309283Z","shell.execute_reply.started":"2023-09-17T05:08:54.543920Z","shell.execute_reply":"2023-09-17T05:11:39.307653Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['angry_011' 117.0 21.0 38.0 17.0]\n['angry_011' 117.0 40.0 55.0 15.0]\n['angry_011' 117.0 60.0 79.0 19.0]\n['angry_011' 117.0 85.0 95.0 10.0]\n['angry_011' 117.0 101.0 110.0 9.0]\n['angry_012' 32.0 0.0 0.02 0.02]\n['angry_013' 72.0 0.0 0.01 0.0]\n['angry_014' 50.0 0.0 0.012 0.0]\n['angry_015' 162.0 64.0 71.0 7.0]\n['angry_015' 162.0 89.0 100.0 11.0]\n['angry_015' 162.0 106.0 116.0 10.0]\n['angry_015' 162.0 130.0 160.0 30.0]\n['angry_016' 15.0 0.0 0.015 0.015]\n['angry_017' 80.0 22.0 60.0 38.0]\n['angry_018' 60.0 21.0 32.0 11.0]\n['angry_018' 60.0 37.0 60.0 23.0]\n['angry_021' 42.0 3.0 5.0 2.0]\n['angry_021' 42.0 19.0 25.0 6.0]\n['angry_022' 35.0 5.0 16.0 11.0]\n['angry_022' 35.0 17.0 26.0 9.0]\n['angry_022' 35.0 29.0 33.0 4.0]\n['angry_023' 34.0 0.0 0.01 0.01]\n['angry_024' 31.0 27.0 30.0 3.0]\n['angry_025' 74.0 60.0 72.0 12.0]\n['angry_026' 89.0 39.0 44.0 5.0]\n['angry_026' 89.0 49.0 52.0 3.0]\n['angry_027' 51.0 7.0 12.0 5.0]\n['angry_027' 51.0 14.0 48.0 34.0]\n['angry_028' 87.0 0.0 0.1 0.1]\n['angry_031' 47.0 1.0 36.0 35.0]\n['angry_032' 73.0 12.0 22.0 10.0]\n['angry_032' 73.0 43.0 48.0 5.0]\n['angry_033' 127.0 0.0 0.1 0.1]\n['angry_034' 23.0 0.0 0.1 0.1]\n['angry_035' 86.0 0.0 36.0 36.0]\n['angry_035' 86.0 41.0 85.0 44.0]\n['angry_036' 79.0 0.0 0.1 0.1]\n['angry_037' 69.0 13.0 68.0 55.0]\n['angry_038' 132.0 4.0 15.0 11.0]\n['angry_038' 132.0 23.0 25.0 2.0]\n['angry_038' 132.0 40.0 44.0 4.0]\n['angry_038' 132.0 53.0 71.0 18.0]\n['angry_038' 132.0 94.0 110.0 16.0]\n['angry_038' 132.0 117.0 122.0 5.0]\n['angry_039' 62.0 47.0 52.0 5.0]\n['angry_041' 42.0 0.0 0.1 0.0]\n['angry_042' 33.0 18.0 20.0 2.0]\n['angry_043' 77.0 2.0 8.0 6.0]\n['angry_043' 77.0 28.0 72.0 44.0]\n['angry_044' 67.0 12.0 66.0 54.0]\n['angry_045' 35.0 1.0 32.0 31.0]\n['angry_046' 51.0 12.0 18.0 6.0]\n['angry_047' 22.0 0.0 0.1 0.1]\n['angry_048' 87.0 18.0 73.0 55.0]\n['angry_049' 34.0 28.0 31.0 3.0]\n['angry_049a' 98.0 0.0 26.0 26.0]\n['angry_049a' 98.0 33.0 42.0 9.0]\n['angry_049a' 98.0 73.0 75.0 2.0]\n['angry_049b' 81.0 5.0 9.0 4.0]\n['angry_051' 52.0 2.0 18.0 16.0]\n['angry_051' 52.0 20.0 30.0 10.0]\n['angry_051' 52.0 35.0 45.0 10.0]\n['angry_052' 73.0 0.0 32.0 32.0]\n['angry_052' 73.0 35.0 73.0 38.0]\n['angry_053' 69.0 0.0 0.1 0.1]\n['angry_054' 99.0 50.0 60.0 10.0]\n['angry_055' 53.0 40.0 42.0 2.0]\n['angry_056' 58.0 0.0 26.0 26.0]\n['angry_056' 58.0 30.0 38.0 8.0]\n['angry_057' 65.0 0.0 6.0 6.0]\n['angry_057' 65.0 14.0 24.0 10.0]\n['angry_057' 65.0 43.0 60.0 17.0]\n['angry_058' 47.0 43.0 46.0 3.0]\n['angry_059' 35.0 0.0 12.0 12.0]\n['angry_061' 68.0 15.0 18.0 3.0]\n['angry_062' 83.0 4.0 15.0 11.0]\n['angry_062' 83.0 21.0 36.0 15.0]\n['angry_062' 83.0 40.0 51.0 11.0]\n['angry_062' 83.0 56.0 81.0 25.0]\n['angry_063' 39.0 0.0 34.0 34.0]\n['angry_064' 39.0 0.0 0.1 0.1]\n['angry_065' 74.0 0.0 23.0 23.0]\n['angry_065' 74.0 27.0 33.0 6.0]\n['angry_065' 74.0 42.0 55.0 13.0]\n['angry_065' 74.0 68.0 71.0 3.0]\n['angry_066' 33.0 28.0 33.0 5.0]\n['angry_067' 119.0 23.0 48.0 25.0]\n['angry_067' 119.0 53.0 72.0 19.0]\n['angry_067' 119.0 117.0 119.0 2.0]\n['angry_071' 74.0 0.0 0.2 0.2]\n['angry_072' 152.0 89.0 93.0 4.0]\n['angry_072' 152.0 95.0 98.0 3.0]\n['angry_072' 152.0 115.0 120.0 5.0]\n['angry_072' 152.0 122.0 126.0 4.0]\n['angry_072' 152.0 137.0 141.0 4.0]\n['angry_073' 128.0 0.0 0.1 0.1]\n['angry_074' 47.0 3.0 34.0 31.0]\n['angry_074' 47.0 37.0 46.0 9.0]\n['angry_075' 125.0 89.0 114.0 25.0]\n['angry_075' 125.0 116.0 118.0 2.0]\n['angry_076' 23.0 0.0 0.1 0.1]\n['angry_077' 75.0 27.0 31.0 4.0]\n['angry_077' 75.0 47.0 49.0 2.0]\n['angry_081' 161.0 8.545 13.375 4.83]\n['angry_081' 161.0 14.025 15.418 1.392999999999999]\n['angry_081' 161.0 16.811 18.112 1.3009999999999984]\n['angry_081' 161.0 26.564 28.7 2.1359999999999992]\n['angry_081' 161.0 32.415 39.474 7.0589999999999975]\n['angry_081' 161.0 41.424 44.118 2.6940000000000026]\n['angry_081' 161.0 45.418 48.948 3.530000000000001]\n['angry_081' 161.0 51.27 54.613 3.3429999999999964]\n['angry_081' 161.0 57.864 61.022 3.1580000000000013]\n['angry_081' 161.0 62.601 70.96 8.358999999999995]\n['angry_081' 161.0 111.27 112.57 1.2999999999999972]\n['angry_081' 161.0 148.515 149.908 1.3930000000000007]\n['angry_082' 145.0 10.867 23.763 12.896]\n['angry_082' 145.0 36.13 39.753 3.6229999999999976]\n['angry_082' 145.0 80.991 87.864 6.873000000000005]\n['angry_082' 145.0 88.236 99.753 11.516999999999996]\n['angry_082' 145.0 118.6 133.3 14.700000000000017]\n['angry_082' 145.0 137.998 140.813 2.8149999999999977]\n['angry_083' 65.0 3.344 8.452 5.1080000000000005]\n['angry_083' 65.0 9.102 13.375 4.273]\n['angry_083' 65.0 15.418 19.598 4.18]\n['angry_083' 65.0 43.282 46.904 3.622000000000007]\n['angry_084' 90.0 5.301 7.251 1.9500000000000002]\n['angry_084' 90.0 12.791 24.494 11.703]\n['angry_084' 90.0 27.657 33.415 5.757999999999999]\n['angry_084' 90.0 36.184 40.828 4.6440000000000055]\n['angry_084' 90.0 54.277 57.342 3.0649999999999977]\n['angry_084' 90.0 58.886 64.923 6.036999999999999]\n['angry_084' 90.0 66.837 69.067 2.2299999999999898]\n['angry_084' 90.0 70.064 77.68 7.616000000000014]\n['angry_085' 26.0 13.235 17.322 4.087]\n['angry_085' 26.0 21.232 24.404 3.1720000000000006]\n['angry_086' 70.0 1.486 6.409 4.923]\n['angry_086' 70.0 10.031 12.539 2.507999999999999]\n['angry_086' 70.0 23.963 32.508 8.545000000000002]\n['angry_086' 70.0 39.381 42.539 3.1580000000000013]\n['angry_086' 70.0 48.855 52.663 3.808]\n['angry_091' 26.0 14.954 19.691 4.736999999999998]\n['angry_091' 26.0 22.43 25.496 3.065999999999999]\n['angry_092' 89.0 57.493 66.13 8.636999999999993]\n['angry_092' 89.0 71.703 75.79 4.087000000000003]\n['angry_093' 49.0 0.698 4.228 3.53]\n['angry_093' 49.0 11.806 21.0 9.194]\n['angry_094' 169.0 14.886 28.911 14.025000000000002]\n['angry_094' 169.0 34.369 45.5 11.131]\n['angry_094' 169.0 49.255 55.385 6.1299999999999955]\n['angry_094' 169.0 59.982 62.211 2.228999999999999]\n['angry_094' 169.0 68.301 70.623 2.3220000000000027]\n['angry_094' 169.0 72.022 77.316 5.293999999999997]\n['angry_094' 169.0 87.127 91.778 4.6510000000000105]\n['angry_094' 169.0 95.883 99.506 3.6230000000000047]\n['angry_094' 169.0 111.207 114.087 2.8800000000000097]\n['angry_094' 169.0 119.307 125.623 6.3160000000000025]\n['angry_094' 169.0 138.79 143.341 4.551000000000016]\n['angry_094' 169.0 148.203 154.0 5.796999999999997]\n['angry_095' 123.0 2.7 23.0 20.3]\n['angry_095' 123.0 55.446 59.254 3.808]\n['angry_095' 123.0 62.615 75.34 12.725000000000001]\n['angry_095' 123.0 77.592 81.214 3.622]\n['angry_095' 123.0 83.965 87.494 3.5289999999999964]\n['angry_095' 123.0 97.348 104.036 6.688000000000002]\n['angry_095' 123.0 106.11 112.706 6.596000000000004]\n['angry_095' 123.0 119.176 123.0 3.823999999999998]\n['angry_101' 94.0 0.0 0.01 0.01]\n['angry_102' 132.0 4.959 7.095 2.136]\n['angry_102' 132.0 55.057 59.051 3.9939999999999998]\n['angry_102' 132.0 62.238 64.096 1.858000000000004]\n['angry_102' 132.0 66.0 68.786 2.7860000000000014]\n['angry_102' 132.0 71.642 76.658 5.016000000000005]\n['angry_102' 132.0 80.876 87.191 6.314999999999998]\n['angry_102' 132.0 93.358 106.082 12.72399999999999]\n['angry_102' 132.0 113.534 115.484 1.9499999999999886]\n['angry_102' 132.0 117.3 132.0 14.700000000000003]\n['angry_103' 108.0 0.0 0.01 0.01]\n['angry_104' 92.0 0.0 5.201 5.201]\n['angry_104' 92.0 6.197 10.562 4.364999999999999]\n['angry_104' 92.0 14.062 20.378 6.316000000000001]\n['angry_104' 92.0 84.254 90.663 6.408999999999992]\n['angry_111' 167.0 11.465 15.645 4.18]\n['angry_111' 167.0 45.644 68.824 23.18]\n['angry_111' 167.0 72.9 77.637 4.736999999999995]\n['angry_111' 167.0 79.174 92.055 12.881]\n['angry_111' 167.0 96.047 101.898 5.850999999999999]\n['angry_111' 167.0 106.214 127.667 21.453000000000003]\n['angry_111' 167.0 133.47 167.0 33.53]\n['angry_112' 243.0 50.992 63.258 12.266000000000005]\n['angry_112' 243.0 77.118 82.412 5.294000000000011]\n['angry_112' 243.0 97.263 111.814 14.550999999999988]\n['angry_112' 243.0 114.89 172.475 57.584999999999994]\n['angry_112' 243.0 194.526 219.975 25.448999999999984]\n['angry_112' 243.0 223.484 227.385 3.900999999999982]\n['angry_112' 243.0 234.816 243.0 8.183999999999997]\n['angry_113' 105.0 0.5 15.233 14.733]\n['angry_113' 105.0 17.137 22.803 5.666]\n['angry_113' 105.0 26.25 28.479 2.228999999999999]\n['angry_113' 105.0 29.922 37.631 7.709]\n['angry_113' 105.0 38.219 40.912 2.692999999999998]\n['angry_113' 105.0 45.835 50.294 4.458999999999996]\n['angry_113' 105.0 54.404 72.33 17.925999999999995]\n['angry_113' 105.0 75.486 80.13 4.643999999999991]\n['angry_113' 105.0 81.198 84.263 3.065000000000012]\n['angry_121' 320.0 61.347 66.27 4.922999999999995]\n['angry_121' 320.0 258.446 264.39 5.94399999999996]\n['angry_122' 401.0 167.457 169.221 1.76400000000001]\n['angry_122' 401.0 309.151 310.358 1.2069999999999936]\n['angry_122' 401.0 345.834 346.67 0.8360000000000127]\n['angry_122' 401.0 354.515 356.094 1.5790000000000077]\n['angry_122' 401.0 395.679 398.93 3.251000000000033]\n['angry_131' 66.0 17.052 66.0 48.948]\n['angry_132' 53.0 0.0 0.01 0.01]\n['angry_133' 83.0 6.055 12.649 6.593999999999999]\n['angry_133' 83.0 17.912 22.556 4.644000000000002]\n['angry_133' 83.0 26.238 28.745 2.5070000000000014]\n['angry_133' 83.0 34.437 38.152 3.7150000000000034]\n['angry_133' 83.0 38.473 40.5 2.027000000000001]\n['angry_133' 83.0 47.682 68.301 20.619]\n['angry_133' 83.0 69.883 76.663 6.780000000000001]\n['angry_134' 276.0 0.0 20.553 20.553]\n['angry_134' 276.0 24.328 165.588 141.26]\n['angry_134' 276.0 168.201 191.271 23.069999999999993]\n['angry_134' 276.0 195.046 200.433 5.3870000000000005]\n['angry_134' 276.0 223.568 228.212 4.643999999999977]\n['angry_141' 176.0 6.419 11.063 4.644000000000001]\n['angry_141' 176.0 84.79 89.063 4.272999999999996]\n['angry_141' 176.0 100.304 102.069 1.7650000000000006]\n['angry_141' 176.0 151.125 153.911 2.7860000000000014]\n['angry_142' 165.0 1.0 14.396 13.396]\n['angry_142' 165.0 98.298 104.335 6.036999999999992]\n['angry_142' 165.0 127.386 132.216 4.8300000000000125]\n['angry_142' 165.0 160.236 162.8 2.5640000000000214]\n['angry_143' 79.058 0.0 9.043 9.043]\n['angry_143' 79.058 10.464 52.318 41.854]\n['angry_143' 79.058 56.193 79.058 22.86500000000001]\n['angry_144' 86.0 7.973 20.326 12.353000000000002]\n['angry_144' 86.0 47.705 57.758 10.053000000000004]\n['angry_144' 86.0 65.872 77.482 11.61]\n['angry_144' 86.0 84.17 86.0 1.8299999999999983]\n['angry_145' 127.0 0.965 4.68 3.715]\n['angry_145' 127.0 6.948 10.849 3.901]\n['angry_145' 127.0 12.546 16.354 3.808]\n['angry_145' 127.0 18.336 28.46 10.124000000000002]\n['angry_145' 127.0 29.916 31.031 1.1149999999999984]\n['angry_145' 127.0 32.812 34.855 2.0429999999999993]\n['angry_145' 127.0 40.339 42.104 1.7650000000000006]\n['angry_145' 127.0 45.936 51.88 5.944000000000003]\n['angry_145' 127.0 53.364 55.0 1.6360000000000028]\n['angry_145' 127.0 59.64 61.962 2.3220000000000027]\n['angry_145' 127.0 63.693 65.458 1.7650000000000006]\n['angry_145' 127.0 66.781 69.568 2.786999999999992]\n['angry_145' 127.0 73.15 85.496 12.34599999999999]\n['angry_145' 127.0 94.96 96.075 1.115000000000009]\n['angry_145' 127.0 114.84 117.627 2.786999999999992]\n['angry_145' 127.0 119.087 121.409 2.3220000000000027]\n['angry_145' 127.0 125.07 127.0 1.9300000000000068]\n['angry_151' 43.0 1.699 5.0 3.301]\n['angry_151' 43.0 6.078 10.536 4.457999999999999]\n['angry_151' 43.0 12.09 15.155 3.0649999999999995]\n['angry_151' 43.0 15.88 16.56 0.6799999999999979]\n['angry_151' 43.0 19.213 23.207 3.9939999999999998]\n['angry_151' 43.0 25.617 33.79 8.172999999999998]\n['angry_151' 43.0 34.439 35.182 0.7430000000000021]\n['angry_151' 43.0 36.138 39.761 3.6230000000000047]\n['angry_151' 43.0 41.17 43.0 1.8299999999999983]\n['angry_152' 103.0 0.0 0.001 0.001]\n['angry_153' 103.0 34.594 37.566 2.9720000000000013]\n['angry_153' 103.0 49.935 52.257 2.3219999999999956]\n['angry_153' 103.0 70.597 71.619 1.0220000000000056]\n['angry_153' 103.0 74.824 80.211 5.3870000000000005]\n['angry_153' 103.0 91.103 93.611 2.5080000000000098]\n['angry_161' 102.0 55.96 58.933 2.972999999999999]\n['angry_161' 102.0 90.219 93.284 3.065000000000012]\n['angry_162' 70.0 34.957 70.0 35.043]\n['angry_171' 98.0 34.255 37.506 3.2509999999999977]\n['angry_171' 98.0 93.234 98.0 4.766000000000005]\n['angry_181' 74.0 0.0 8.7 8.7]\n['angry_181' 74.0 10.347 12.297 1.950000000000001]\n['angry_181' 74.0 13.158 19.753 6.595000000000001]\n['angry_181' 74.0 22.605 26.784 4.1789999999999985]\n['angry_181' 74.0 31.939 41.599 9.659999999999997]\n['angry_181' 74.0 50.046 60.0 9.954]\n['angry_181' 74.0 61.629 65.53 3.9010000000000034]\n['angry_181' 74.0 68.827 70.684 1.8569999999999993]\n['angry_182' 93.0 39.292 41.057 1.7650000000000006]\n['angry_182' 93.0 42.401 45.745 3.343999999999994]\n['angry_182' 93.0 72.93 73.673 0.742999999999995]\n['angry_182' 93.0 75.474 76.96 1.48599999999999]\n['angry_191' 152.0 44.815 47.229 2.4140000000000015]\n['angry_191' 152.0 117.119 119.905 2.7860000000000014]\n['angry_191' 152.0 126.359 129.702 3.3430000000000035]\n['angry_191' 152.0 131.672 144.489 12.817000000000007]\n['angry_192' 60.0 56.261 58.769 2.5079999999999956]\n['angry_193' 153.0 0.93 24.614 23.684]\n['angry_193' 153.0 32.0 57.201 25.201]\n['angry_193' 153.0 76.035 78.264 2.228999999999999]\n['angry_193' 153.0 79.0 81.519 2.5190000000000055]\n['angry_193' 153.0 85.801 105.938 20.137]\n['angry_193' 153.0 107.0 153.0 46.0]\n['angry_201' 173.0 33.653 48.2 14.547000000000004]\n['angry_201' 173.0 49.954 52.648 2.6940000000000026]\n['angry_201' 173.0 62.049 72.265 10.216000000000001]\n['angry_201' 173.0 79.927 88.008 8.080999999999989]\n['angry_201' 173.0 104.904 114.9 9.99600000000001]\n['angry_201' 173.0 119.891 122.863 2.971999999999994]\n['angry_201' 173.0 128.041 130.827 2.7860000000000014]\n['angry_201' 173.0 164.061 173.0 8.938999999999993]\n['angry_202' 323.015 290.615 299.811 9.19599999999997]\n['angry_203' 28.0 1.574 3.525 1.9509999999999998]\n['angry_203' 28.0 5.319 28.0 22.681]\n['angry_204' 243.0 0.0 2.136 2.136]\n['angry_204' 243.0 5.44 6.097 0.657]\n['angry_204' 243.0 25.851 39.319 13.468000000000004]\n['angry_204' 243.0 48.378 49.6 1.2220000000000013]\n['angry_204' 243.0 51.702 53.002 1.3000000000000043]\n['angry_204' 243.0 56.3 65.236 8.936000000000007]\n['angry_204' 243.0 69.798 79.495 9.697000000000003]\n['angry_204' 243.0 87.894 94.67 6.775999999999996]\n['angry_204' 243.0 131.84 133.698 1.858000000000004]\n['angry_204' 243.0 159.169 163.534 4.364999999999981]\n['angry_204' 243.0 176.895 182.468 5.572999999999979]\n['angry_204' 243.0 183.543 187.908 4.364999999999981]\n['angry_204' 243.0 191.667 198.726 7.0589999999999975]\n['angry_204' 243.0 201.638 208.047 6.408999999999992]\n['angry_204' 243.0 210.132 214.498 4.3659999999999854]\n['angry_204' 243.0 215.302 217.624 2.3220000000000027]\n['angry_204' 243.0 220.842 223.814 2.97199999999998]\n['angry_204' 243.0 238.199 243.0 4.800999999999988]\n['angry_205' 49.0 12.957 32.989 20.031999999999996]\n['angry_205' 49.0 34.851 36.059 1.2079999999999984]\n['angry_205' 49.0 38.053 38.796 0.7430000000000021]\n['angry_205' 49.0 48.106 49.0 0.8939999999999984]\n['angry_211' 149.0 49.365 54.38 5.015000000000001]\n['angry_211' 149.0 67.707 90.369 22.662000000000006]\n['angry_211' 149.0 98.05 102.601 4.551000000000002]\n['angry_211' 149.0 108.014 121.203 13.189000000000007]\n['noviolence_01' 4939.0 0.0 0.01 0.01]\n['noviolence_02' 4476.0 0.0 0.01 0.01]\n['noviolence_03' 4966.0 0.0 0.01 0.01]\n['noviolence_04' 3731.0 0.0 0.01 0.01]\n","output_type":"stream"}]},{"cell_type":"code","source":"from pydub import AudioSegment\nimport math\n\nfor record in metadata.values:\n    print(record)\n    t1 = 1000 * record[2]\n    t2 = 1000 * record[3]\n    audio  = AudioSegment.from_wav(os.path.join(\"../input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD\",str(record[0])+\".wav\"))\n    non_violence_segment = audio[0:t1]\n    non_violence_segment.export(os.path.join(non_violence_dir,record[0]+\"_non_violence.wav\"))\n    non_violence_segment = audio[t2:]\n    non_violence_segment.export(os.path.join(non_violence_dir,record[0]+\"_non_violence2.wav\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:11:39.311535Z","iopub.execute_input":"2023-09-17T05:11:39.312121Z","iopub.status.idle":"2023-09-17T05:32:12.299950Z","shell.execute_reply.started":"2023-09-17T05:11:39.312065Z","shell.execute_reply":"2023-09-17T05:32:12.297167Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['angry_011' 117.0 21.0 38.0 17.0]\n['angry_011' 117.0 40.0 55.0 15.0]\n['angry_011' 117.0 60.0 79.0 19.0]\n['angry_011' 117.0 85.0 95.0 10.0]\n['angry_011' 117.0 101.0 110.0 9.0]\n['angry_012' 32.0 0.0 0.02 0.02]\n['angry_013' 72.0 0.0 0.01 0.0]\n['angry_014' 50.0 0.0 0.012 0.0]\n['angry_015' 162.0 64.0 71.0 7.0]\n['angry_015' 162.0 89.0 100.0 11.0]\n['angry_015' 162.0 106.0 116.0 10.0]\n['angry_015' 162.0 130.0 160.0 30.0]\n['angry_016' 15.0 0.0 0.015 0.015]\n['angry_017' 80.0 22.0 60.0 38.0]\n['angry_018' 60.0 21.0 32.0 11.0]\n['angry_018' 60.0 37.0 60.0 23.0]\n['angry_021' 42.0 3.0 5.0 2.0]\n['angry_021' 42.0 19.0 25.0 6.0]\n['angry_022' 35.0 5.0 16.0 11.0]\n['angry_022' 35.0 17.0 26.0 9.0]\n['angry_022' 35.0 29.0 33.0 4.0]\n['angry_023' 34.0 0.0 0.01 0.01]\n['angry_024' 31.0 27.0 30.0 3.0]\n['angry_025' 74.0 60.0 72.0 12.0]\n['angry_026' 89.0 39.0 44.0 5.0]\n['angry_026' 89.0 49.0 52.0 3.0]\n['angry_027' 51.0 7.0 12.0 5.0]\n['angry_027' 51.0 14.0 48.0 34.0]\n['angry_028' 87.0 0.0 0.1 0.1]\n['angry_031' 47.0 1.0 36.0 35.0]\n['angry_032' 73.0 12.0 22.0 10.0]\n['angry_032' 73.0 43.0 48.0 5.0]\n['angry_033' 127.0 0.0 0.1 0.1]\n['angry_034' 23.0 0.0 0.1 0.1]\n['angry_035' 86.0 0.0 36.0 36.0]\n['angry_035' 86.0 41.0 85.0 44.0]\n['angry_036' 79.0 0.0 0.1 0.1]\n['angry_037' 69.0 13.0 68.0 55.0]\n['angry_038' 132.0 4.0 15.0 11.0]\n['angry_038' 132.0 23.0 25.0 2.0]\n['angry_038' 132.0 40.0 44.0 4.0]\n['angry_038' 132.0 53.0 71.0 18.0]\n['angry_038' 132.0 94.0 110.0 16.0]\n['angry_038' 132.0 117.0 122.0 5.0]\n['angry_039' 62.0 47.0 52.0 5.0]\n['angry_041' 42.0 0.0 0.1 0.0]\n['angry_042' 33.0 18.0 20.0 2.0]\n['angry_043' 77.0 2.0 8.0 6.0]\n['angry_043' 77.0 28.0 72.0 44.0]\n['angry_044' 67.0 12.0 66.0 54.0]\n['angry_045' 35.0 1.0 32.0 31.0]\n['angry_046' 51.0 12.0 18.0 6.0]\n['angry_047' 22.0 0.0 0.1 0.1]\n['angry_048' 87.0 18.0 73.0 55.0]\n['angry_049' 34.0 28.0 31.0 3.0]\n['angry_049a' 98.0 0.0 26.0 26.0]\n['angry_049a' 98.0 33.0 42.0 9.0]\n['angry_049a' 98.0 73.0 75.0 2.0]\n['angry_049b' 81.0 5.0 9.0 4.0]\n['angry_051' 52.0 2.0 18.0 16.0]\n['angry_051' 52.0 20.0 30.0 10.0]\n['angry_051' 52.0 35.0 45.0 10.0]\n['angry_052' 73.0 0.0 32.0 32.0]\n['angry_052' 73.0 35.0 73.0 38.0]\n['angry_053' 69.0 0.0 0.1 0.1]\n['angry_054' 99.0 50.0 60.0 10.0]\n['angry_055' 53.0 40.0 42.0 2.0]\n['angry_056' 58.0 0.0 26.0 26.0]\n['angry_056' 58.0 30.0 38.0 8.0]\n['angry_057' 65.0 0.0 6.0 6.0]\n['angry_057' 65.0 14.0 24.0 10.0]\n['angry_057' 65.0 43.0 60.0 17.0]\n['angry_058' 47.0 43.0 46.0 3.0]\n['angry_059' 35.0 0.0 12.0 12.0]\n['angry_061' 68.0 15.0 18.0 3.0]\n['angry_062' 83.0 4.0 15.0 11.0]\n['angry_062' 83.0 21.0 36.0 15.0]\n['angry_062' 83.0 40.0 51.0 11.0]\n['angry_062' 83.0 56.0 81.0 25.0]\n['angry_063' 39.0 0.0 34.0 34.0]\n['angry_064' 39.0 0.0 0.1 0.1]\n['angry_065' 74.0 0.0 23.0 23.0]\n['angry_065' 74.0 27.0 33.0 6.0]\n['angry_065' 74.0 42.0 55.0 13.0]\n['angry_065' 74.0 68.0 71.0 3.0]\n['angry_066' 33.0 28.0 33.0 5.0]\n['angry_067' 119.0 23.0 48.0 25.0]\n['angry_067' 119.0 53.0 72.0 19.0]\n['angry_067' 119.0 117.0 119.0 2.0]\n['angry_071' 74.0 0.0 0.2 0.2]\n['angry_072' 152.0 89.0 93.0 4.0]\n['angry_072' 152.0 95.0 98.0 3.0]\n['angry_072' 152.0 115.0 120.0 5.0]\n['angry_072' 152.0 122.0 126.0 4.0]\n['angry_072' 152.0 137.0 141.0 4.0]\n['angry_073' 128.0 0.0 0.1 0.1]\n['angry_074' 47.0 3.0 34.0 31.0]\n['angry_074' 47.0 37.0 46.0 9.0]\n['angry_075' 125.0 89.0 114.0 25.0]\n['angry_075' 125.0 116.0 118.0 2.0]\n['angry_076' 23.0 0.0 0.1 0.1]\n['angry_077' 75.0 27.0 31.0 4.0]\n['angry_077' 75.0 47.0 49.0 2.0]\n['angry_081' 161.0 8.545 13.375 4.83]\n['angry_081' 161.0 14.025 15.418 1.392999999999999]\n['angry_081' 161.0 16.811 18.112 1.3009999999999984]\n['angry_081' 161.0 26.564 28.7 2.1359999999999992]\n['angry_081' 161.0 32.415 39.474 7.0589999999999975]\n['angry_081' 161.0 41.424 44.118 2.6940000000000026]\n['angry_081' 161.0 45.418 48.948 3.530000000000001]\n['angry_081' 161.0 51.27 54.613 3.3429999999999964]\n['angry_081' 161.0 57.864 61.022 3.1580000000000013]\n['angry_081' 161.0 62.601 70.96 8.358999999999995]\n['angry_081' 161.0 111.27 112.57 1.2999999999999972]\n['angry_081' 161.0 148.515 149.908 1.3930000000000007]\n['angry_082' 145.0 10.867 23.763 12.896]\n['angry_082' 145.0 36.13 39.753 3.6229999999999976]\n['angry_082' 145.0 80.991 87.864 6.873000000000005]\n['angry_082' 145.0 88.236 99.753 11.516999999999996]\n['angry_082' 145.0 118.6 133.3 14.700000000000017]\n['angry_082' 145.0 137.998 140.813 2.8149999999999977]\n['angry_083' 65.0 3.344 8.452 5.1080000000000005]\n['angry_083' 65.0 9.102 13.375 4.273]\n['angry_083' 65.0 15.418 19.598 4.18]\n['angry_083' 65.0 43.282 46.904 3.622000000000007]\n['angry_084' 90.0 5.301 7.251 1.9500000000000002]\n['angry_084' 90.0 12.791 24.494 11.703]\n['angry_084' 90.0 27.657 33.415 5.757999999999999]\n['angry_084' 90.0 36.184 40.828 4.6440000000000055]\n['angry_084' 90.0 54.277 57.342 3.0649999999999977]\n['angry_084' 90.0 58.886 64.923 6.036999999999999]\n['angry_084' 90.0 66.837 69.067 2.2299999999999898]\n['angry_084' 90.0 70.064 77.68 7.616000000000014]\n['angry_085' 26.0 13.235 17.322 4.087]\n['angry_085' 26.0 21.232 24.404 3.1720000000000006]\n['angry_086' 70.0 1.486 6.409 4.923]\n['angry_086' 70.0 10.031 12.539 2.507999999999999]\n['angry_086' 70.0 23.963 32.508 8.545000000000002]\n['angry_086' 70.0 39.381 42.539 3.1580000000000013]\n['angry_086' 70.0 48.855 52.663 3.808]\n['angry_091' 26.0 14.954 19.691 4.736999999999998]\n['angry_091' 26.0 22.43 25.496 3.065999999999999]\n['angry_092' 89.0 57.493 66.13 8.636999999999993]\n['angry_092' 89.0 71.703 75.79 4.087000000000003]\n['angry_093' 49.0 0.698 4.228 3.53]\n['angry_093' 49.0 11.806 21.0 9.194]\n['angry_094' 169.0 14.886 28.911 14.025000000000002]\n['angry_094' 169.0 34.369 45.5 11.131]\n['angry_094' 169.0 49.255 55.385 6.1299999999999955]\n['angry_094' 169.0 59.982 62.211 2.228999999999999]\n['angry_094' 169.0 68.301 70.623 2.3220000000000027]\n['angry_094' 169.0 72.022 77.316 5.293999999999997]\n['angry_094' 169.0 87.127 91.778 4.6510000000000105]\n['angry_094' 169.0 95.883 99.506 3.6230000000000047]\n['angry_094' 169.0 111.207 114.087 2.8800000000000097]\n['angry_094' 169.0 119.307 125.623 6.3160000000000025]\n['angry_094' 169.0 138.79 143.341 4.551000000000016]\n['angry_094' 169.0 148.203 154.0 5.796999999999997]\n['angry_095' 123.0 2.7 23.0 20.3]\n['angry_095' 123.0 55.446 59.254 3.808]\n['angry_095' 123.0 62.615 75.34 12.725000000000001]\n['angry_095' 123.0 77.592 81.214 3.622]\n['angry_095' 123.0 83.965 87.494 3.5289999999999964]\n['angry_095' 123.0 97.348 104.036 6.688000000000002]\n['angry_095' 123.0 106.11 112.706 6.596000000000004]\n['angry_095' 123.0 119.176 123.0 3.823999999999998]\n['angry_101' 94.0 0.0 0.01 0.01]\n['angry_102' 132.0 4.959 7.095 2.136]\n['angry_102' 132.0 55.057 59.051 3.9939999999999998]\n['angry_102' 132.0 62.238 64.096 1.858000000000004]\n['angry_102' 132.0 66.0 68.786 2.7860000000000014]\n['angry_102' 132.0 71.642 76.658 5.016000000000005]\n['angry_102' 132.0 80.876 87.191 6.314999999999998]\n['angry_102' 132.0 93.358 106.082 12.72399999999999]\n['angry_102' 132.0 113.534 115.484 1.9499999999999886]\n['angry_102' 132.0 117.3 132.0 14.700000000000003]\n['angry_103' 108.0 0.0 0.01 0.01]\n['angry_104' 92.0 0.0 5.201 5.201]\n['angry_104' 92.0 6.197 10.562 4.364999999999999]\n['angry_104' 92.0 14.062 20.378 6.316000000000001]\n['angry_104' 92.0 84.254 90.663 6.408999999999992]\n['angry_111' 167.0 11.465 15.645 4.18]\n['angry_111' 167.0 45.644 68.824 23.18]\n['angry_111' 167.0 72.9 77.637 4.736999999999995]\n['angry_111' 167.0 79.174 92.055 12.881]\n['angry_111' 167.0 96.047 101.898 5.850999999999999]\n['angry_111' 167.0 106.214 127.667 21.453000000000003]\n['angry_111' 167.0 133.47 167.0 33.53]\n['angry_112' 243.0 50.992 63.258 12.266000000000005]\n['angry_112' 243.0 77.118 82.412 5.294000000000011]\n['angry_112' 243.0 97.263 111.814 14.550999999999988]\n['angry_112' 243.0 114.89 172.475 57.584999999999994]\n['angry_112' 243.0 194.526 219.975 25.448999999999984]\n['angry_112' 243.0 223.484 227.385 3.900999999999982]\n['angry_112' 243.0 234.816 243.0 8.183999999999997]\n['angry_113' 105.0 0.5 15.233 14.733]\n['angry_113' 105.0 17.137 22.803 5.666]\n['angry_113' 105.0 26.25 28.479 2.228999999999999]\n['angry_113' 105.0 29.922 37.631 7.709]\n['angry_113' 105.0 38.219 40.912 2.692999999999998]\n['angry_113' 105.0 45.835 50.294 4.458999999999996]\n['angry_113' 105.0 54.404 72.33 17.925999999999995]\n['angry_113' 105.0 75.486 80.13 4.643999999999991]\n['angry_113' 105.0 81.198 84.263 3.065000000000012]\n['angry_121' 320.0 61.347 66.27 4.922999999999995]\n['angry_121' 320.0 258.446 264.39 5.94399999999996]\n['angry_122' 401.0 167.457 169.221 1.76400000000001]\n['angry_122' 401.0 309.151 310.358 1.2069999999999936]\n['angry_122' 401.0 345.834 346.67 0.8360000000000127]\n['angry_122' 401.0 354.515 356.094 1.5790000000000077]\n['angry_122' 401.0 395.679 398.93 3.251000000000033]\n['angry_131' 66.0 17.052 66.0 48.948]\n['angry_132' 53.0 0.0 0.01 0.01]\n['angry_133' 83.0 6.055 12.649 6.593999999999999]\n['angry_133' 83.0 17.912 22.556 4.644000000000002]\n['angry_133' 83.0 26.238 28.745 2.5070000000000014]\n['angry_133' 83.0 34.437 38.152 3.7150000000000034]\n['angry_133' 83.0 38.473 40.5 2.027000000000001]\n['angry_133' 83.0 47.682 68.301 20.619]\n['angry_133' 83.0 69.883 76.663 6.780000000000001]\n['angry_134' 276.0 0.0 20.553 20.553]\n['angry_134' 276.0 24.328 165.588 141.26]\n['angry_134' 276.0 168.201 191.271 23.069999999999993]\n['angry_134' 276.0 195.046 200.433 5.3870000000000005]\n['angry_134' 276.0 223.568 228.212 4.643999999999977]\n['angry_141' 176.0 6.419 11.063 4.644000000000001]\n['angry_141' 176.0 84.79 89.063 4.272999999999996]\n['angry_141' 176.0 100.304 102.069 1.7650000000000006]\n['angry_141' 176.0 151.125 153.911 2.7860000000000014]\n['angry_142' 165.0 1.0 14.396 13.396]\n['angry_142' 165.0 98.298 104.335 6.036999999999992]\n['angry_142' 165.0 127.386 132.216 4.8300000000000125]\n['angry_142' 165.0 160.236 162.8 2.5640000000000214]\n['angry_143' 79.058 0.0 9.043 9.043]\n['angry_143' 79.058 10.464 52.318 41.854]\n['angry_143' 79.058 56.193 79.058 22.86500000000001]\n['angry_144' 86.0 7.973 20.326 12.353000000000002]\n['angry_144' 86.0 47.705 57.758 10.053000000000004]\n['angry_144' 86.0 65.872 77.482 11.61]\n['angry_144' 86.0 84.17 86.0 1.8299999999999983]\n['angry_145' 127.0 0.965 4.68 3.715]\n['angry_145' 127.0 6.948 10.849 3.901]\n['angry_145' 127.0 12.546 16.354 3.808]\n['angry_145' 127.0 18.336 28.46 10.124000000000002]\n['angry_145' 127.0 29.916 31.031 1.1149999999999984]\n['angry_145' 127.0 32.812 34.855 2.0429999999999993]\n['angry_145' 127.0 40.339 42.104 1.7650000000000006]\n['angry_145' 127.0 45.936 51.88 5.944000000000003]\n['angry_145' 127.0 53.364 55.0 1.6360000000000028]\n['angry_145' 127.0 59.64 61.962 2.3220000000000027]\n['angry_145' 127.0 63.693 65.458 1.7650000000000006]\n['angry_145' 127.0 66.781 69.568 2.786999999999992]\n['angry_145' 127.0 73.15 85.496 12.34599999999999]\n['angry_145' 127.0 94.96 96.075 1.115000000000009]\n['angry_145' 127.0 114.84 117.627 2.786999999999992]\n['angry_145' 127.0 119.087 121.409 2.3220000000000027]\n['angry_145' 127.0 125.07 127.0 1.9300000000000068]\n['angry_151' 43.0 1.699 5.0 3.301]\n['angry_151' 43.0 6.078 10.536 4.457999999999999]\n['angry_151' 43.0 12.09 15.155 3.0649999999999995]\n['angry_151' 43.0 15.88 16.56 0.6799999999999979]\n['angry_151' 43.0 19.213 23.207 3.9939999999999998]\n['angry_151' 43.0 25.617 33.79 8.172999999999998]\n['angry_151' 43.0 34.439 35.182 0.7430000000000021]\n['angry_151' 43.0 36.138 39.761 3.6230000000000047]\n['angry_151' 43.0 41.17 43.0 1.8299999999999983]\n['angry_152' 103.0 0.0 0.001 0.001]\n['angry_153' 103.0 34.594 37.566 2.9720000000000013]\n['angry_153' 103.0 49.935 52.257 2.3219999999999956]\n['angry_153' 103.0 70.597 71.619 1.0220000000000056]\n['angry_153' 103.0 74.824 80.211 5.3870000000000005]\n['angry_153' 103.0 91.103 93.611 2.5080000000000098]\n['angry_161' 102.0 55.96 58.933 2.972999999999999]\n['angry_161' 102.0 90.219 93.284 3.065000000000012]\n['angry_162' 70.0 34.957 70.0 35.043]\n['angry_171' 98.0 34.255 37.506 3.2509999999999977]\n['angry_171' 98.0 93.234 98.0 4.766000000000005]\n['angry_181' 74.0 0.0 8.7 8.7]\n['angry_181' 74.0 10.347 12.297 1.950000000000001]\n['angry_181' 74.0 13.158 19.753 6.595000000000001]\n['angry_181' 74.0 22.605 26.784 4.1789999999999985]\n['angry_181' 74.0 31.939 41.599 9.659999999999997]\n['angry_181' 74.0 50.046 60.0 9.954]\n['angry_181' 74.0 61.629 65.53 3.9010000000000034]\n['angry_181' 74.0 68.827 70.684 1.8569999999999993]\n['angry_182' 93.0 39.292 41.057 1.7650000000000006]\n['angry_182' 93.0 42.401 45.745 3.343999999999994]\n['angry_182' 93.0 72.93 73.673 0.742999999999995]\n['angry_182' 93.0 75.474 76.96 1.48599999999999]\n['angry_191' 152.0 44.815 47.229 2.4140000000000015]\n['angry_191' 152.0 117.119 119.905 2.7860000000000014]\n['angry_191' 152.0 126.359 129.702 3.3430000000000035]\n['angry_191' 152.0 131.672 144.489 12.817000000000007]\n['angry_192' 60.0 56.261 58.769 2.5079999999999956]\n['angry_193' 153.0 0.93 24.614 23.684]\n['angry_193' 153.0 32.0 57.201 25.201]\n['angry_193' 153.0 76.035 78.264 2.228999999999999]\n['angry_193' 153.0 79.0 81.519 2.5190000000000055]\n['angry_193' 153.0 85.801 105.938 20.137]\n['angry_193' 153.0 107.0 153.0 46.0]\n['angry_201' 173.0 33.653 48.2 14.547000000000004]\n['angry_201' 173.0 49.954 52.648 2.6940000000000026]\n['angry_201' 173.0 62.049 72.265 10.216000000000001]\n['angry_201' 173.0 79.927 88.008 8.080999999999989]\n['angry_201' 173.0 104.904 114.9 9.99600000000001]\n['angry_201' 173.0 119.891 122.863 2.971999999999994]\n['angry_201' 173.0 128.041 130.827 2.7860000000000014]\n['angry_201' 173.0 164.061 173.0 8.938999999999993]\n['angry_202' 323.015 290.615 299.811 9.19599999999997]\n['angry_203' 28.0 1.574 3.525 1.9509999999999998]\n['angry_203' 28.0 5.319 28.0 22.681]\n['angry_204' 243.0 0.0 2.136 2.136]\n['angry_204' 243.0 5.44 6.097 0.657]\n['angry_204' 243.0 25.851 39.319 13.468000000000004]\n['angry_204' 243.0 48.378 49.6 1.2220000000000013]\n['angry_204' 243.0 51.702 53.002 1.3000000000000043]\n['angry_204' 243.0 56.3 65.236 8.936000000000007]\n['angry_204' 243.0 69.798 79.495 9.697000000000003]\n['angry_204' 243.0 87.894 94.67 6.775999999999996]\n['angry_204' 243.0 131.84 133.698 1.858000000000004]\n['angry_204' 243.0 159.169 163.534 4.364999999999981]\n['angry_204' 243.0 176.895 182.468 5.572999999999979]\n['angry_204' 243.0 183.543 187.908 4.364999999999981]\n['angry_204' 243.0 191.667 198.726 7.0589999999999975]\n['angry_204' 243.0 201.638 208.047 6.408999999999992]\n['angry_204' 243.0 210.132 214.498 4.3659999999999854]\n['angry_204' 243.0 215.302 217.624 2.3220000000000027]\n['angry_204' 243.0 220.842 223.814 2.97199999999998]\n['angry_204' 243.0 238.199 243.0 4.800999999999988]\n['angry_205' 49.0 12.957 32.989 20.031999999999996]\n['angry_205' 49.0 34.851 36.059 1.2079999999999984]\n['angry_205' 49.0 38.053 38.796 0.7430000000000021]\n['angry_205' 49.0 48.106 49.0 0.8939999999999984]\n['angry_211' 149.0 49.365 54.38 5.015000000000001]\n['angry_211' 149.0 67.707 90.369 22.662000000000006]\n['angry_211' 149.0 98.05 102.601 4.551000000000002]\n['angry_211' 149.0 108.014 121.203 13.189000000000007]\n['noviolence_01' 4939.0 0.0 0.01 0.01]\n['noviolence_02' 4476.0 0.0 0.01 0.01]\n['noviolence_03' 4966.0 0.0 0.01 0.01]\n['noviolence_04' 3731.0 0.0 0.01 0.01]\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"#audio_df = pd.DataFrame({\"audio_clip\":[], \"violence_label\":[]})\naudio_clip=[]\nviolence_labe=[]\nfor record in metadata.values:\n    audio_clip.append(AudioSegment.from_wav(os.path.join(violence_dir,record[0]+\".wav\")))\n    violence_label.append(1)\n    audio_cip.append(AudioSegment.from_wav(os.path.join(non_violence_dir,record[0]+\".wav\")))\n    violence_label.append(0)\n\naudio_df = pd.DataFrame({\"audio_clip\":[], \"violence_label\":[]})\naudio_df.head(20)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:32:12.304010Z","iopub.execute_input":"2023-09-17T05:32:12.305728Z","iopub.status.idle":"2023-09-17T05:32:12.319748Z","shell.execute_reply.started":"2023-09-17T05:32:12.305679Z","shell.execute_reply":"2023-09-17T05:32:12.318430Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'#audio_df = pd.DataFrame({\"audio_clip\":[], \"violence_label\":[]})\\naudio_clip=[]\\nviolence_labe=[]\\nfor record in metadata.values:\\n    audio_clip.append(AudioSegment.from_wav(os.path.join(violence_dir,record[0]+\".wav\")))\\n    violence_label.append(1)\\n    audio_cip.append(AudioSegment.from_wav(os.path.join(non_violence_dir,record[0]+\".wav\")))\\n    violence_label.append(0)\\n\\naudio_df = pd.DataFrame({\"audio_clip\":[], \"violence_label\":[]})\\naudio_df.head(20)'"},"metadata":{}}]},{"cell_type":"code","source":"import librosa\n\ndef features_extractor(file):\n    #load the file (audio)\n    #audio, sample_rate = librosa.load(file, res_type='kaiser_fast')\n    audio, sample_rate = librosa.load(file) \n    \n    #we extract mfcc\n    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n    #in order to find out scaled feature we do mean of transpose of value\n    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n    return mfccs_scaled_features","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:32:12.321783Z","iopub.execute_input":"2023-09-17T05:32:12.322212Z","iopub.status.idle":"2023-09-17T05:32:12.359008Z","shell.execute_reply.started":"2023-09-17T05:32:12.322180Z","shell.execute_reply":"2023-09-17T05:32:12.357668Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(\"Check\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:32:12.360892Z","iopub.execute_input":"2023-09-17T05:32:12.361267Z","iopub.status.idle":"2023-09-17T05:32:12.380186Z","shell.execute_reply.started":"2023-09-17T05:32:12.361236Z","shell.execute_reply":"2023-09-17T05:32:12.378627Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Check\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install resampy\n#Now we ned to extract the featured from all the audio files so we use tqdm\nimport numpy as np\nfrom tqdm import tqdm\n### Now we iterate through every audio file and extract features \n### using Mel-Frequency Cepstral Coefficients\nextracted_features=[]\n\"\"\"for index_num,row in tqdm(metadata.iterrows()):\n    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    final_class_labels=row[\"class\"]\n    data=features_extractor(file_name)\n    extracted_features.append([data,final_class_labels])\"\"\"\n\n\nfor record in metadata.values:\n    file_name = os.path.join(os.path.abspath(violence_dir),record[0]+\".wav\")\n    print(file_name)\n    final_class_labels=1\n    try:\n        data=features_extractor(file_name)\n    except:\n        continue\n    extracted_features.append([data,final_class_labels])\n    #violence_segment.export(os.path.join(violence_dir,record[0]+\".wav\"))\n        \nfor record in metadata.values:\n    file_name = os.path.join(os.path.abspath(non_violence_dir),record[0]+\"_non_violence.wav\")\n    print(file_name)\n    final_class_labels=0\n    try:\n        data=features_extractor(file_name)\n    except:\n        continue\n    extracted_features.append([data,final_class_labels])\n\"\"\"    \nfor record in metadata.values:\n    file_name = os.path.join(os.path.abspath(non_violence_dir),record[0]+\"_non_violence2.wav\")\n    print(file_name)\n    final_class_labels=0\n    try:\n        data=features_extractor(file_name)\n    except:\n        continue\n    extracted_features.append([data,final_class_labels])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-17T05:58:48.874888Z","iopub.execute_input":"2023-09-17T05:58:48.876661Z","iopub.status.idle":"2023-09-17T06:02:15.856749Z","shell.execute_reply.started":"2023-09-17T05:58:48.876594Z","shell.execute_reply":"2023-09-17T06:02:15.854808Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"/kaggle/violence_data/angry_011.wav\n/kaggle/violence_data/angry_011.wav\n/kaggle/violence_data/angry_011.wav\n/kaggle/violence_data/angry_011.wav\n/kaggle/violence_data/angry_011.wav\n/kaggle/violence_data/angry_012.wav\n/kaggle/violence_data/angry_013.wav\n/kaggle/violence_data/angry_014.wav\n/kaggle/violence_data/angry_015.wav\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=441\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=221\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=265\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/violence_data/angry_015.wav\n/kaggle/violence_data/angry_015.wav\n/kaggle/violence_data/angry_015.wav\n/kaggle/violence_data/angry_016.wav\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=331\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/violence_data/angry_017.wav\n/kaggle/violence_data/angry_018.wav\n/kaggle/violence_data/angry_018.wav\n/kaggle/violence_data/angry_021.wav\n/kaggle/violence_data/angry_021.wav\n/kaggle/violence_data/angry_022.wav\n/kaggle/violence_data/angry_022.wav\n/kaggle/violence_data/angry_022.wav\n/kaggle/violence_data/angry_023.wav\n/kaggle/violence_data/angry_024.wav\n/kaggle/violence_data/angry_025.wav\n/kaggle/violence_data/angry_026.wav\n/kaggle/violence_data/angry_026.wav\n/kaggle/violence_data/angry_027.wav\n/kaggle/violence_data/angry_027.wav\n/kaggle/violence_data/angry_028.wav\n/kaggle/violence_data/angry_031.wav\n/kaggle/violence_data/angry_032.wav\n/kaggle/violence_data/angry_032.wav\n/kaggle/violence_data/angry_033.wav\n/kaggle/violence_data/angry_034.wav\n/kaggle/violence_data/angry_035.wav\n/kaggle/violence_data/angry_035.wav\n/kaggle/violence_data/angry_036.wav\n/kaggle/violence_data/angry_037.wav\n/kaggle/violence_data/angry_038.wav\n/kaggle/violence_data/angry_038.wav\n/kaggle/violence_data/angry_038.wav\n/kaggle/violence_data/angry_038.wav\n/kaggle/violence_data/angry_038.wav\n/kaggle/violence_data/angry_038.wav\n/kaggle/violence_data/angry_039.wav\n/kaggle/violence_data/angry_041.wav\n/kaggle/violence_data/angry_042.wav\n/kaggle/violence_data/angry_043.wav\n/kaggle/violence_data/angry_043.wav\n/kaggle/violence_data/angry_044.wav\n/kaggle/violence_data/angry_045.wav\n/kaggle/violence_data/angry_046.wav\n/kaggle/violence_data/angry_047.wav\n/kaggle/violence_data/angry_048.wav\n/kaggle/violence_data/angry_049.wav\n/kaggle/violence_data/angry_049a.wav\n/kaggle/violence_data/angry_049a.wav\n/kaggle/violence_data/angry_049a.wav\n/kaggle/violence_data/angry_049b.wav\n/kaggle/violence_data/angry_051.wav\n/kaggle/violence_data/angry_051.wav\n/kaggle/violence_data/angry_051.wav\n/kaggle/violence_data/angry_052.wav\n/kaggle/violence_data/angry_052.wav\n/kaggle/violence_data/angry_053.wav\n/kaggle/violence_data/angry_054.wav\n/kaggle/violence_data/angry_055.wav\n/kaggle/violence_data/angry_056.wav\n/kaggle/violence_data/angry_056.wav\n/kaggle/violence_data/angry_057.wav\n/kaggle/violence_data/angry_057.wav\n/kaggle/violence_data/angry_057.wav\n/kaggle/violence_data/angry_058.wav\n/kaggle/violence_data/angry_059.wav\n/kaggle/violence_data/angry_061.wav\n/kaggle/violence_data/angry_062.wav\n/kaggle/violence_data/angry_062.wav\n/kaggle/violence_data/angry_062.wav\n/kaggle/violence_data/angry_062.wav\n/kaggle/violence_data/angry_063.wav\n/kaggle/violence_data/angry_064.wav\n/kaggle/violence_data/angry_065.wav\n/kaggle/violence_data/angry_065.wav\n/kaggle/violence_data/angry_065.wav\n/kaggle/violence_data/angry_065.wav\n/kaggle/violence_data/angry_066.wav\n/kaggle/violence_data/angry_067.wav\n/kaggle/violence_data/angry_067.wav\n/kaggle/violence_data/angry_067.wav\n/kaggle/violence_data/angry_071.wav\n/kaggle/violence_data/angry_072.wav\n/kaggle/violence_data/angry_072.wav\n/kaggle/violence_data/angry_072.wav\n/kaggle/violence_data/angry_072.wav\n/kaggle/violence_data/angry_072.wav\n/kaggle/violence_data/angry_073.wav\n/kaggle/violence_data/angry_074.wav\n/kaggle/violence_data/angry_074.wav\n/kaggle/violence_data/angry_075.wav\n/kaggle/violence_data/angry_075.wav\n/kaggle/violence_data/angry_076.wav\n/kaggle/violence_data/angry_077.wav\n/kaggle/violence_data/angry_077.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_081.wav\n/kaggle/violence_data/angry_082.wav\n/kaggle/violence_data/angry_082.wav\n/kaggle/violence_data/angry_082.wav\n/kaggle/violence_data/angry_082.wav\n/kaggle/violence_data/angry_082.wav\n/kaggle/violence_data/angry_082.wav\n/kaggle/violence_data/angry_083.wav\n/kaggle/violence_data/angry_083.wav\n/kaggle/violence_data/angry_083.wav\n/kaggle/violence_data/angry_083.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_084.wav\n/kaggle/violence_data/angry_085.wav\n/kaggle/violence_data/angry_085.wav\n/kaggle/violence_data/angry_086.wav\n/kaggle/violence_data/angry_086.wav\n/kaggle/violence_data/angry_086.wav\n/kaggle/violence_data/angry_086.wav\n/kaggle/violence_data/angry_086.wav\n/kaggle/violence_data/angry_091.wav\n/kaggle/violence_data/angry_091.wav\n/kaggle/violence_data/angry_092.wav\n/kaggle/violence_data/angry_092.wav\n/kaggle/violence_data/angry_093.wav\n/kaggle/violence_data/angry_093.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_094.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_095.wav\n/kaggle/violence_data/angry_101.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_102.wav\n/kaggle/violence_data/angry_103.wav\n/kaggle/violence_data/angry_104.wav\n/kaggle/violence_data/angry_104.wav\n/kaggle/violence_data/angry_104.wav\n/kaggle/violence_data/angry_104.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_111.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_112.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_113.wav\n/kaggle/violence_data/angry_121.wav\n/kaggle/violence_data/angry_121.wav\n/kaggle/violence_data/angry_122.wav\n/kaggle/violence_data/angry_122.wav\n/kaggle/violence_data/angry_122.wav\n/kaggle/violence_data/angry_122.wav\n/kaggle/violence_data/angry_122.wav\n/kaggle/violence_data/angry_131.wav\n/kaggle/violence_data/angry_132.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_133.wav\n/kaggle/violence_data/angry_134.wav\n/kaggle/violence_data/angry_134.wav\n/kaggle/violence_data/angry_134.wav\n/kaggle/violence_data/angry_134.wav\n/kaggle/violence_data/angry_134.wav\n/kaggle/violence_data/angry_141.wav\n/kaggle/violence_data/angry_141.wav\n/kaggle/violence_data/angry_141.wav\n/kaggle/violence_data/angry_141.wav\n/kaggle/violence_data/angry_142.wav\n/kaggle/violence_data/angry_142.wav\n/kaggle/violence_data/angry_142.wav\n/kaggle/violence_data/angry_142.wav\n/kaggle/violence_data/angry_143.wav\n/kaggle/violence_data/angry_143.wav\n/kaggle/violence_data/angry_143.wav\n/kaggle/violence_data/angry_144.wav\n/kaggle/violence_data/angry_144.wav\n/kaggle/violence_data/angry_144.wav\n/kaggle/violence_data/angry_144.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_145.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_151.wav\n/kaggle/violence_data/angry_152.wav\n/kaggle/violence_data/angry_153.wav\n/kaggle/violence_data/angry_153.wav\n/kaggle/violence_data/angry_153.wav\n/kaggle/violence_data/angry_153.wav\n/kaggle/violence_data/angry_153.wav\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=24\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/violence_data/angry_161.wav\n/kaggle/violence_data/angry_161.wav\n/kaggle/violence_data/angry_162.wav\n/kaggle/violence_data/angry_171.wav\n/kaggle/violence_data/angry_171.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_181.wav\n/kaggle/violence_data/angry_182.wav\n/kaggle/violence_data/angry_182.wav\n/kaggle/violence_data/angry_182.wav\n/kaggle/violence_data/angry_182.wav\n/kaggle/violence_data/angry_191.wav\n/kaggle/violence_data/angry_191.wav\n/kaggle/violence_data/angry_191.wav\n/kaggle/violence_data/angry_191.wav\n/kaggle/violence_data/angry_192.wav\n/kaggle/violence_data/angry_193.wav\n/kaggle/violence_data/angry_193.wav\n/kaggle/violence_data/angry_193.wav\n/kaggle/violence_data/angry_193.wav\n/kaggle/violence_data/angry_193.wav\n/kaggle/violence_data/angry_193.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_201.wav\n/kaggle/violence_data/angry_202.wav\n/kaggle/violence_data/angry_203.wav\n/kaggle/violence_data/angry_203.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_204.wav\n/kaggle/violence_data/angry_205.wav\n/kaggle/violence_data/angry_205.wav\n/kaggle/violence_data/angry_205.wav\n/kaggle/violence_data/angry_205.wav\n/kaggle/violence_data/angry_211.wav\n/kaggle/violence_data/angry_211.wav\n/kaggle/violence_data/angry_211.wav\n/kaggle/violence_data/angry_211.wav\n/kaggle/violence_data/noviolence_01.wav\n/kaggle/violence_data/noviolence_02.wav\n/kaggle/violence_data/noviolence_03.wav\n/kaggle/violence_data/noviolence_04.wav\n/kaggle/non_violence_data/angry_011_non_violence.wav\n/kaggle/non_violence_data/angry_011_non_violence.wav\n/kaggle/non_violence_data/angry_011_non_violence.wav\n/kaggle/non_violence_data/angry_011_non_violence.wav\n/kaggle/non_violence_data/angry_011_non_violence.wav\n/kaggle/non_violence_data/angry_012_non_violence.wav\n/kaggle/non_violence_data/angry_013_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_014_non_violence.wav\n/kaggle/non_violence_data/angry_015_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_015_non_violence.wav\n/kaggle/non_violence_data/angry_015_non_violence.wav\n/kaggle/non_violence_data/angry_015_non_violence.wav\n/kaggle/non_violence_data/angry_016_non_violence.wav\n/kaggle/non_violence_data/angry_017_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_018_non_violence.wav\n/kaggle/non_violence_data/angry_018_non_violence.wav\n/kaggle/non_violence_data/angry_021_non_violence.wav\n/kaggle/non_violence_data/angry_021_non_violence.wav\n/kaggle/non_violence_data/angry_022_non_violence.wav\n/kaggle/non_violence_data/angry_022_non_violence.wav\n/kaggle/non_violence_data/angry_022_non_violence.wav\n/kaggle/non_violence_data/angry_023_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_024_non_violence.wav\n/kaggle/non_violence_data/angry_025_non_violence.wav\n/kaggle/non_violence_data/angry_026_non_violence.wav\n/kaggle/non_violence_data/angry_026_non_violence.wav\n/kaggle/non_violence_data/angry_027_non_violence.wav\n/kaggle/non_violence_data/angry_027_non_violence.wav\n/kaggle/non_violence_data/angry_028_non_violence.wav\n/kaggle/non_violence_data/angry_031_non_violence.wav\n/kaggle/non_violence_data/angry_032_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_032_non_violence.wav\n/kaggle/non_violence_data/angry_033_non_violence.wav\n/kaggle/non_violence_data/angry_034_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_035_non_violence.wav\n/kaggle/non_violence_data/angry_035_non_violence.wav\n/kaggle/non_violence_data/angry_036_non_violence.wav\n/kaggle/non_violence_data/angry_037_non_violence.wav\n/kaggle/non_violence_data/angry_038_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_038_non_violence.wav\n/kaggle/non_violence_data/angry_038_non_violence.wav\n/kaggle/non_violence_data/angry_038_non_violence.wav\n/kaggle/non_violence_data/angry_038_non_violence.wav\n/kaggle/non_violence_data/angry_038_non_violence.wav\n/kaggle/non_violence_data/angry_039_non_violence.wav\n/kaggle/non_violence_data/angry_041_non_violence.wav\n/kaggle/non_violence_data/angry_042_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_043_non_violence.wav\n/kaggle/non_violence_data/angry_043_non_violence.wav\n/kaggle/non_violence_data/angry_044_non_violence.wav\n/kaggle/non_violence_data/angry_045_non_violence.wav\n/kaggle/non_violence_data/angry_046_non_violence.wav\n/kaggle/non_violence_data/angry_047_non_violence.wav\n/kaggle/non_violence_data/angry_048_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_049_non_violence.wav\n/kaggle/non_violence_data/angry_049a_non_violence.wav\n/kaggle/non_violence_data/angry_049a_non_violence.wav\n/kaggle/non_violence_data/angry_049a_non_violence.wav\n/kaggle/non_violence_data/angry_049b_non_violence.wav\n/kaggle/non_violence_data/angry_051_non_violence.wav\n/kaggle/non_violence_data/angry_051_non_violence.wav\n/kaggle/non_violence_data/angry_051_non_violence.wav\n/kaggle/non_violence_data/angry_052_non_violence.wav\n/kaggle/non_violence_data/angry_052_non_violence.wav\n/kaggle/non_violence_data/angry_053_non_violence.wav\n/kaggle/non_violence_data/angry_054_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_055_non_violence.wav\n/kaggle/non_violence_data/angry_056_non_violence.wav\n/kaggle/non_violence_data/angry_056_non_violence.wav\n/kaggle/non_violence_data/angry_057_non_violence.wav\n/kaggle/non_violence_data/angry_057_non_violence.wav\n/kaggle/non_violence_data/angry_057_non_violence.wav\n/kaggle/non_violence_data/angry_058_non_violence.wav\n/kaggle/non_violence_data/angry_059_non_violence.wav\n/kaggle/non_violence_data/angry_061_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_062_non_violence.wav\n/kaggle/non_violence_data/angry_062_non_violence.wav\n/kaggle/non_violence_data/angry_062_non_violence.wav\n/kaggle/non_violence_data/angry_062_non_violence.wav\n/kaggle/non_violence_data/angry_063_non_violence.wav\n/kaggle/non_violence_data/angry_064_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_065_non_violence.wav\n/kaggle/non_violence_data/angry_065_non_violence.wav\n/kaggle/non_violence_data/angry_065_non_violence.wav\n/kaggle/non_violence_data/angry_065_non_violence.wav\n/kaggle/non_violence_data/angry_066_non_violence.wav\n/kaggle/non_violence_data/angry_067_non_violence.wav\n/kaggle/non_violence_data/angry_067_non_violence.wav\n/kaggle/non_violence_data/angry_067_non_violence.wav\n/kaggle/non_violence_data/angry_071_non_violence.wav\n/kaggle/non_violence_data/angry_072_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_072_non_violence.wav\n/kaggle/non_violence_data/angry_072_non_violence.wav\n/kaggle/non_violence_data/angry_072_non_violence.wav\n/kaggle/non_violence_data/angry_072_non_violence.wav\n/kaggle/non_violence_data/angry_073_non_violence.wav\n/kaggle/non_violence_data/angry_074_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_074_non_violence.wav\n/kaggle/non_violence_data/angry_075_non_violence.wav\n/kaggle/non_violence_data/angry_075_non_violence.wav\n/kaggle/non_violence_data/angry_076_non_violence.wav\n/kaggle/non_violence_data/angry_077_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_077_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_081_non_violence.wav\n/kaggle/non_violence_data/angry_082_non_violence.wav\n/kaggle/non_violence_data/angry_082_non_violence.wav\n/kaggle/non_violence_data/angry_082_non_violence.wav\n/kaggle/non_violence_data/angry_082_non_violence.wav\n/kaggle/non_violence_data/angry_082_non_violence.wav\n/kaggle/non_violence_data/angry_082_non_violence.wav\n/kaggle/non_violence_data/angry_083_non_violence.wav\n/kaggle/non_violence_data/angry_083_non_violence.wav\n/kaggle/non_violence_data/angry_083_non_violence.wav\n/kaggle/non_violence_data/angry_083_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_084_non_violence.wav\n/kaggle/non_violence_data/angry_085_non_violence.wav\n/kaggle/non_violence_data/angry_085_non_violence.wav\n/kaggle/non_violence_data/angry_086_non_violence.wav\n/kaggle/non_violence_data/angry_086_non_violence.wav\n/kaggle/non_violence_data/angry_086_non_violence.wav\n/kaggle/non_violence_data/angry_086_non_violence.wav\n/kaggle/non_violence_data/angry_086_non_violence.wav\n/kaggle/non_violence_data/angry_091_non_violence.wav\n/kaggle/non_violence_data/angry_091_non_violence.wav\n/kaggle/non_violence_data/angry_092_non_violence.wav\n/kaggle/non_violence_data/angry_092_non_violence.wav\n/kaggle/non_violence_data/angry_093_non_violence.wav\n/kaggle/non_violence_data/angry_093_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_094_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_095_non_violence.wav\n/kaggle/non_violence_data/angry_101_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_102_non_violence.wav\n/kaggle/non_violence_data/angry_103_non_violence.wav\n/kaggle/non_violence_data/angry_104_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_104_non_violence.wav\n/kaggle/non_violence_data/angry_104_non_violence.wav\n/kaggle/non_violence_data/angry_104_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_111_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_112_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_113_non_violence.wav\n/kaggle/non_violence_data/angry_121_non_violence.wav\n/kaggle/non_violence_data/angry_121_non_violence.wav\n/kaggle/non_violence_data/angry_122_non_violence.wav\n/kaggle/non_violence_data/angry_122_non_violence.wav\n/kaggle/non_violence_data/angry_122_non_violence.wav\n/kaggle/non_violence_data/angry_122_non_violence.wav\n/kaggle/non_violence_data/angry_122_non_violence.wav\n/kaggle/non_violence_data/angry_131_non_violence.wav\n/kaggle/non_violence_data/angry_132_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_133_non_violence.wav\n/kaggle/non_violence_data/angry_134_non_violence.wav\n/kaggle/non_violence_data/angry_134_non_violence.wav\n/kaggle/non_violence_data/angry_134_non_violence.wav\n/kaggle/non_violence_data/angry_134_non_violence.wav\n/kaggle/non_violence_data/angry_134_non_violence.wav\n/kaggle/non_violence_data/angry_141_non_violence.wav\n/kaggle/non_violence_data/angry_141_non_violence.wav\n/kaggle/non_violence_data/angry_141_non_violence.wav\n/kaggle/non_violence_data/angry_141_non_violence.wav\n/kaggle/non_violence_data/angry_142_non_violence.wav\n/kaggle/non_violence_data/angry_142_non_violence.wav\n/kaggle/non_violence_data/angry_142_non_violence.wav\n/kaggle/non_violence_data/angry_142_non_violence.wav\n/kaggle/non_violence_data/angry_143_non_violence.wav\n/kaggle/non_violence_data/angry_143_non_violence.wav\n/kaggle/non_violence_data/angry_143_non_violence.wav\n/kaggle/non_violence_data/angry_144_non_violence.wav\n/kaggle/non_violence_data/angry_144_non_violence.wav\n/kaggle/non_violence_data/angry_144_non_violence.wav\n/kaggle/non_violence_data/angry_144_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_145_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_151_non_violence.wav\n/kaggle/non_violence_data/angry_152_non_violence.wav\n/kaggle/non_violence_data/angry_153_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/angry_153_non_violence.wav\n/kaggle/non_violence_data/angry_153_non_violence.wav\n/kaggle/non_violence_data/angry_153_non_violence.wav\n/kaggle/non_violence_data/angry_153_non_violence.wav\n/kaggle/non_violence_data/angry_161_non_violence.wav\n/kaggle/non_violence_data/angry_161_non_violence.wav\n/kaggle/non_violence_data/angry_162_non_violence.wav\n/kaggle/non_violence_data/angry_171_non_violence.wav\n/kaggle/non_violence_data/angry_171_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_181_non_violence.wav\n/kaggle/non_violence_data/angry_182_non_violence.wav\n/kaggle/non_violence_data/angry_182_non_violence.wav\n/kaggle/non_violence_data/angry_182_non_violence.wav\n/kaggle/non_violence_data/angry_182_non_violence.wav\n/kaggle/non_violence_data/angry_191_non_violence.wav\n/kaggle/non_violence_data/angry_191_non_violence.wav\n/kaggle/non_violence_data/angry_191_non_violence.wav\n/kaggle/non_violence_data/angry_191_non_violence.wav\n/kaggle/non_violence_data/angry_192_non_violence.wav\n/kaggle/non_violence_data/angry_193_non_violence.wav\n/kaggle/non_violence_data/angry_193_non_violence.wav\n/kaggle/non_violence_data/angry_193_non_violence.wav\n/kaggle/non_violence_data/angry_193_non_violence.wav\n/kaggle/non_violence_data/angry_193_non_violence.wav\n/kaggle/non_violence_data/angry_193_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_201_non_violence.wav\n/kaggle/non_violence_data/angry_202_non_violence.wav\n/kaggle/non_violence_data/angry_203_non_violence.wav\n/kaggle/non_violence_data/angry_203_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_204_non_violence.wav\n/kaggle/non_violence_data/angry_205_non_violence.wav\n/kaggle/non_violence_data/angry_205_non_violence.wav\n/kaggle/non_violence_data/angry_205_non_violence.wav\n/kaggle/non_violence_data/angry_205_non_violence.wav\n/kaggle/non_violence_data/angry_211_non_violence.wav\n/kaggle/non_violence_data/angry_211_non_violence.wav\n/kaggle/non_violence_data/angry_211_non_violence.wav\n/kaggle/non_violence_data/angry_211_non_violence.wav\n/kaggle/non_violence_data/noviolence_01_non_violence.wav\n/kaggle/non_violence_data/noviolence_02_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/non_violence_data/noviolence_03_non_violence.wav\n/kaggle/non_violence_data/noviolence_04_non_violence.wav\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n/tmp/ipykernel_32/3047486539.py:6: UserWarning: PySoundFile failed. Trying audioread instead.\n  audio, sample_rate = librosa.load(file)\n/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n\tDeprecated as of librosa version 0.10.0.\n\tIt will be removed in librosa version 1.0.\n  y, sr_native = __audioread_load(path, offset, duration, dtype)\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'    \\nfor record in metadata.values:\\n    file_name = os.path.join(os.path.abspath(non_violence_dir),record[0]+\"_non_violence2.wav\")\\n    print(file_name)\\n    final_class_labels=0\\n    try:\\n        data=features_extractor(file_name)\\n    except:\\n        continue\\n    extracted_features.append([data,final_class_labels])\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### converting extracted_features to Pandas dataframe\nextracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\nextracted_features_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T06:03:23.032119Z","iopub.execute_input":"2023-09-17T06:03:23.032616Z","iopub.status.idle":"2023-09-17T06:03:23.052251Z","shell.execute_reply.started":"2023-09-17T06:03:23.032581Z","shell.execute_reply":"2023-09-17T06:03:23.050953Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"                                             feature  class\n0  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n1  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n2  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n3  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n4  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"extracted_features_df[\"class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T06:03:32.242666Z","iopub.execute_input":"2023-09-17T06:03:32.243148Z","iopub.status.idle":"2023-09-17T06:03:32.253306Z","shell.execute_reply.started":"2023-09-17T06:03:32.243112Z","shell.execute_reply":"2023-09-17T06:03:32.251698Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"class\n1    341\n0    315\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"### Split the dataset into independent and dependent dataset\nX=np.array(extracted_features_df[\"feature\"].tolist())\ny=np.array(extracted_features_df[\"class\"].tolist())\n### Train Test Split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T06:25:56.509231Z","iopub.execute_input":"2023-09-17T06:25:56.509791Z","iopub.status.idle":"2023-09-17T06:25:56.522044Z","shell.execute_reply.started":"2023-09-17T06:25:56.509756Z","shell.execute_reply":"2023-09-17T06:25:56.520911Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:20:23.671214Z","iopub.execute_input":"2023-09-17T07:20:23.671918Z","iopub.status.idle":"2023-09-17T07:20:23.681085Z","shell.execute_reply.started":"2023-09-17T07:20:23.671867Z","shell.execute_reply":"2023-09-17T07:20:23.679945Z"},"trusted":true},"execution_count":191,"outputs":[{"execution_count":191,"output_type":"execute_result","data":{"text/plain":"(66, 40)"},"metadata":{}}]},{"cell_type":"code","source":"X_train=X_train.reshape(590,1,40)\nX_test=X_test.reshape(66,1, 40)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:21:30.501531Z","iopub.execute_input":"2023-09-17T07:21:30.502047Z","iopub.status.idle":"2023-09-17T07:21:30.513130Z","shell.execute_reply.started":"2023-09-17T07:21:30.502010Z","shell.execute_reply":"2023-09-17T07:21:30.511365Z"},"trusted":true},"execution_count":195,"outputs":[{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"(590, 1, 40)"},"metadata":{}}]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:21:35.495323Z","iopub.execute_input":"2023-09-17T07:21:35.495805Z","iopub.status.idle":"2023-09-17T07:21:35.504208Z","shell.execute_reply.started":"2023-09-17T07:21:35.495771Z","shell.execute_reply":"2023-09-17T07:21:35.502706Z"},"trusted":true},"execution_count":196,"outputs":[{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"(656,)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,SimpleRNN, LSTM\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn import metrics\n### No of classes\nnum_labels=y.shape[0]\nmodel=Sequential()\nmodel.add(LSTM(64,input_shape=(1,40)))\n###first layer\nmodel.add(Dense(32))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n###second layer\n#model.add(Dense(128))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.4))\n###third layer\n#model.add(Dense(64))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n###4th layer\n#model.add(Dense(32))\n#model.add(Activation('relu'))\n###5th layer\n#model.add(Dense(16))\n#model.add(Activation('relu'))\n###6th layer\n#model.add(Dense(8))\n#model.add(Activation('relu'))\n###final layer\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:22:38.318160Z","iopub.execute_input":"2023-09-17T07:22:38.318729Z","iopub.status.idle":"2023-09-17T07:22:38.783806Z","shell.execute_reply.started":"2023-09-17T07:22:38.318688Z","shell.execute_reply":"2023-09-17T07:22:38.782364Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:22:46.038468Z","iopub.execute_input":"2023-09-17T07:22:46.040040Z","iopub.status.idle":"2023-09-17T07:22:46.069748Z","shell.execute_reply.started":"2023-09-17T07:22:46.039987Z","shell.execute_reply":"2023-09-17T07:22:46.067877Z"},"trusted":true},"execution_count":201,"outputs":[{"name":"stdout","text":"Model: \"sequential_29\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm_15 (LSTM)              (None, 64)                26880     \n                                                                 \n dense_72 (Dense)            (None, 32)                2080      \n                                                                 \n dense_73 (Dense)            (None, 1)                 33        \n                                                                 \n activation_67 (Activation)  (None, 1)                 0         \n                                                                 \n=================================================================\nTotal params: 28,993\nTrainable params: 28,993\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:22:42.956499Z","iopub.execute_input":"2023-09-17T07:22:42.957846Z","iopub.status.idle":"2023-09-17T07:22:44.533132Z","shell.execute_reply.started":"2023-09-17T07:22:42.957805Z","shell.execute_reply":"2023-09-17T07:22:44.531924Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"model.build()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:19:18.427965Z","iopub.status.idle":"2023-09-17T07:19:18.428980Z","shell.execute_reply.started":"2023-09-17T07:19:18.428743Z","shell.execute_reply":"2023-09-17T07:19:18.428766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import tensorflow as tf\n\n# Create the RNN model\nmodel = tf.keras.Sequential([\n  tf.keras.layers.LSTM(128, input_shape=(X_train.shape[1:])),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\"\"\"\n## Trianing my model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom datetime import datetime \nnum_epochs = 100\nnum_batch_size = 32\ncheckpointer = ModelCheckpoint(filepath='./audio_classification.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\nmodel.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:22:50.516767Z","iopub.execute_input":"2023-09-17T07:22:50.517596Z","iopub.status.idle":"2023-09-17T07:23:13.706663Z","shell.execute_reply.started":"2023-09-17T07:22:50.517552Z","shell.execute_reply":"2023-09-17T07:23:13.704726Z"},"trusted":true},"execution_count":202,"outputs":[{"name":"stdout","text":"Epoch 1/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.6560 - accuracy: 0.6138 \nEpoch 1: val_loss improved from inf to 0.63237, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 4s 43ms/step - loss: 0.6444 - accuracy: 0.6356 - val_loss: 0.6324 - val_accuracy: 0.6212\nEpoch 2/100\n12/19 [=================>............] - ETA: 0s - loss: 0.5836 - accuracy: 0.7109\nEpoch 2: val_loss improved from 0.63237 to 0.53808, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.5772 - accuracy: 0.6966 - val_loss: 0.5381 - val_accuracy: 0.6970\nEpoch 3/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.5203 - accuracy: 0.7620\nEpoch 3: val_loss did not improve from 0.53808\n19/19 [==============================] - 0s 7ms/step - loss: 0.5168 - accuracy: 0.7644 - val_loss: 0.5464 - val_accuracy: 0.6515\nEpoch 4/100\n12/19 [=================>............] - ETA: 0s - loss: 0.4762 - accuracy: 0.7891\nEpoch 4: val_loss improved from 0.53808 to 0.46343, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.4647 - accuracy: 0.7983 - val_loss: 0.4634 - val_accuracy: 0.7424\nEpoch 5/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.4128 - accuracy: 0.8365\nEpoch 5: val_loss improved from 0.46343 to 0.42598, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8339 - val_loss: 0.4260 - val_accuracy: 0.7424\nEpoch 6/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.3682 - accuracy: 0.8479\nEpoch 6: val_loss improved from 0.42598 to 0.42098, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.3499 - accuracy: 0.8644 - val_loss: 0.4210 - val_accuracy: 0.7879\nEpoch 7/100\n18/19 [===========================>..] - ETA: 0s - loss: 0.3036 - accuracy: 0.8889\nEpoch 7: val_loss improved from 0.42098 to 0.35174, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 10ms/step - loss: 0.3047 - accuracy: 0.8864 - val_loss: 0.3517 - val_accuracy: 0.8485\nEpoch 8/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.2646 - accuracy: 0.9087\nEpoch 8: val_loss improved from 0.35174 to 0.33411, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.2727 - accuracy: 0.9085 - val_loss: 0.3341 - val_accuracy: 0.8333\nEpoch 9/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.2533 - accuracy: 0.8951\nEpoch 9: val_loss improved from 0.33411 to 0.32279, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.9051 - val_loss: 0.3228 - val_accuracy: 0.8636\nEpoch 10/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.2065 - accuracy: 0.9354\nEpoch 10: val_loss improved from 0.32279 to 0.29044, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.2111 - accuracy: 0.9288 - val_loss: 0.2904 - val_accuracy: 0.8485\nEpoch 11/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.1893 - accuracy: 0.9330\nEpoch 11: val_loss improved from 0.29044 to 0.28180, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.9339 - val_loss: 0.2818 - val_accuracy: 0.8485\nEpoch 12/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.1738 - accuracy: 0.9399\nEpoch 12: val_loss improved from 0.28180 to 0.23381, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.1665 - accuracy: 0.9424 - val_loss: 0.2338 - val_accuracy: 0.9242\nEpoch 13/100\n12/19 [=================>............] - ETA: 0s - loss: 0.1553 - accuracy: 0.9557\nEpoch 13: val_loss improved from 0.23381 to 0.19096, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.9525 - val_loss: 0.1910 - val_accuracy: 0.9242\nEpoch 14/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.1434 - accuracy: 0.9543\nEpoch 14: val_loss did not improve from 0.19096\n19/19 [==============================] - 0s 7ms/step - loss: 0.1388 - accuracy: 0.9576 - val_loss: 0.1970 - val_accuracy: 0.9394\nEpoch 15/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.1141 - accuracy: 0.9567\nEpoch 15: val_loss improved from 0.19096 to 0.16309, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.1289 - accuracy: 0.9542 - val_loss: 0.1631 - val_accuracy: 0.9545\nEpoch 16/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.1247 - accuracy: 0.9688\nEpoch 16: val_loss did not improve from 0.16309\n19/19 [==============================] - 0s 7ms/step - loss: 0.1171 - accuracy: 0.9678 - val_loss: 0.1640 - val_accuracy: 0.9545\nEpoch 17/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0937 - accuracy: 0.9784\nEpoch 17: val_loss improved from 0.16309 to 0.15453, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0975 - accuracy: 0.9780 - val_loss: 0.1545 - val_accuracy: 0.9545\nEpoch 18/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0911 - accuracy: 0.9784\nEpoch 18: val_loss improved from 0.15453 to 0.14827, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0876 - accuracy: 0.9746 - val_loss: 0.1483 - val_accuracy: 0.9545\nEpoch 19/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0776 - accuracy: 0.9844\nEpoch 19: val_loss improved from 0.14827 to 0.11810, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9780 - val_loss: 0.1181 - val_accuracy: 0.9545\nEpoch 20/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0624 - accuracy: 0.9821\nEpoch 20: val_loss did not improve from 0.11810\n19/19 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9763 - val_loss: 0.1223 - val_accuracy: 0.9545\nEpoch 21/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0692 - accuracy: 0.9821\nEpoch 21: val_loss did not improve from 0.11810\n19/19 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9847 - val_loss: 0.1284 - val_accuracy: 0.9394\nEpoch 22/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0610 - accuracy: 0.9896\nEpoch 22: val_loss did not improve from 0.11810\n19/19 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9898 - val_loss: 0.1247 - val_accuracy: 0.9545\nEpoch 23/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0595 - accuracy: 0.9799\nEpoch 23: val_loss improved from 0.11810 to 0.11481, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9831 - val_loss: 0.1148 - val_accuracy: 0.9394\nEpoch 24/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0498 - accuracy: 0.9933\nEpoch 24: val_loss did not improve from 0.11481\n19/19 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9932 - val_loss: 0.1228 - val_accuracy: 0.9091\nEpoch 25/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0425 - accuracy: 0.9928\nEpoch 25: val_loss improved from 0.11481 to 0.09551, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9932 - val_loss: 0.0955 - val_accuracy: 0.9394\nEpoch 26/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0414 - accuracy: 0.9952\nEpoch 26: val_loss improved from 0.09551 to 0.09383, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0448 - accuracy: 0.9915 - val_loss: 0.0938 - val_accuracy: 0.9394\nEpoch 27/100\n12/19 [=================>............] - ETA: 0s - loss: 0.0412 - accuracy: 0.9948\nEpoch 27: val_loss did not improve from 0.09383\n19/19 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9915 - val_loss: 0.1067 - val_accuracy: 0.9394\nEpoch 28/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0326 - accuracy: 0.9976\nEpoch 28: val_loss did not improve from 0.09383\n19/19 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9949 - val_loss: 0.1032 - val_accuracy: 0.9394\nEpoch 29/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0333 - accuracy: 0.9958\nEpoch 29: val_loss improved from 0.09383 to 0.09236, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9949 - val_loss: 0.0924 - val_accuracy: 0.9394\nEpoch 30/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0305 - accuracy: 0.9952\nEpoch 30: val_loss improved from 0.09236 to 0.08329, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9949 - val_loss: 0.0833 - val_accuracy: 0.9394\nEpoch 31/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0305 - accuracy: 0.9928\nEpoch 31: val_loss improved from 0.08329 to 0.06878, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9932 - val_loss: 0.0688 - val_accuracy: 0.9394\nEpoch 32/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0290 - accuracy: 0.9937\nEpoch 32: val_loss did not improve from 0.06878\n19/19 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9949 - val_loss: 0.0807 - val_accuracy: 0.9394\nEpoch 33/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0269 - accuracy: 0.9937\nEpoch 33: val_loss did not improve from 0.06878\n19/19 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.0864 - val_accuracy: 0.9394\nEpoch 34/100\n10/19 [==============>...............] - ETA: 0s - loss: 0.0130 - accuracy: 0.9969\nEpoch 34: val_loss did not improve from 0.06878\n19/19 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9949 - val_loss: 0.0770 - val_accuracy: 0.9394\nEpoch 35/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0258 - accuracy: 0.9928\nEpoch 35: val_loss did not improve from 0.06878\n19/19 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.0750 - val_accuracy: 0.9394\nEpoch 36/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0196 - accuracy: 0.9978\nEpoch 36: val_loss improved from 0.06878 to 0.06816, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.0682 - val_accuracy: 0.9394\nEpoch 37/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0232 - accuracy: 0.9958\nEpoch 37: val_loss did not improve from 0.06816\n19/19 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9966 - val_loss: 0.1027 - val_accuracy: 0.9394\nEpoch 38/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0219 - accuracy: 0.9955\nEpoch 38: val_loss improved from 0.06816 to 0.05800, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0580 - val_accuracy: 0.9545\nEpoch 39/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0228 - accuracy: 0.9976\nEpoch 39: val_loss did not improve from 0.05800\n19/19 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9983 - val_loss: 0.0805 - val_accuracy: 0.9394\nEpoch 40/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0171 - accuracy: 0.9933\nEpoch 40: val_loss improved from 0.05800 to 0.05054, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0505 - val_accuracy: 0.9848\nEpoch 41/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0190 - accuracy: 0.9952\nEpoch 41: val_loss did not improve from 0.05054\n19/19 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0665 - val_accuracy: 0.9545\nEpoch 42/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0143 - accuracy: 0.9978\nEpoch 42: val_loss did not improve from 0.05054\n19/19 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 0.0717 - val_accuracy: 0.9394\nEpoch 43/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0168 - accuracy: 0.9928\nEpoch 43: val_loss did not improve from 0.05054\n19/19 [==============================] - 0s 6ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0723 - val_accuracy: 0.9545\nEpoch 44/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0145 - accuracy: 0.9976\nEpoch 44: val_loss improved from 0.05054 to 0.04667, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.0467 - val_accuracy: 0.9697\nEpoch 45/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\nEpoch 45: val_loss improved from 0.04667 to 0.04586, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.0459 - val_accuracy: 0.9697\nEpoch 46/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0169 - accuracy: 0.9955\nEpoch 46: val_loss did not improve from 0.04586\n19/19 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0714 - val_accuracy: 0.9545\nEpoch 47/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\nEpoch 47: val_loss did not improve from 0.04586\n19/19 [==============================] - 0s 6ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.0574 - val_accuracy: 0.9545\nEpoch 48/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\nEpoch 48: val_loss did not improve from 0.04586\n19/19 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.0499 - val_accuracy: 0.9697\nEpoch 49/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\nEpoch 49: val_loss did not improve from 0.04586\n19/19 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9697\nEpoch 50/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\nEpoch 50: val_loss improved from 0.04586 to 0.03736, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9697\nEpoch 51/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\nEpoch 51: val_loss did not improve from 0.03736\n19/19 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9242\nEpoch 52/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0123 - accuracy: 0.9978\nEpoch 52: val_loss did not improve from 0.03736\n19/19 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0427 - val_accuracy: 0.9697\nEpoch 53/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\nEpoch 53: val_loss did not improve from 0.03736\n19/19 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9697\nEpoch 54/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\nEpoch 54: val_loss improved from 0.03736 to 0.03515, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 0.9697\nEpoch 55/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\nEpoch 55: val_loss did not improve from 0.03515\n19/19 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9545\nEpoch 56/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\nEpoch 56: val_loss did not improve from 0.03515\n19/19 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9697\nEpoch 57/100\n12/19 [=================>............] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\nEpoch 57: val_loss did not improve from 0.03515\n19/19 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9697\nEpoch 58/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\nEpoch 58: val_loss improved from 0.03515 to 0.03441, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9697\nEpoch 59/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\nEpoch 59: val_loss did not improve from 0.03441\n19/19 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9697\nEpoch 60/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000\nEpoch 60: val_loss improved from 0.03441 to 0.03078, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9697\nEpoch 61/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\nEpoch 61: val_loss improved from 0.03078 to 0.03038, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9848\nEpoch 62/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\nEpoch 62: val_loss improved from 0.03038 to 0.02776, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9848\nEpoch 63/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\nEpoch 63: val_loss improved from 0.02776 to 0.02735, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9848\nEpoch 64/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\nEpoch 64: val_loss improved from 0.02735 to 0.02592, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9848\nEpoch 65/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \nEpoch 65: val_loss did not improve from 0.02592\n19/19 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9848\nEpoch 66/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\nEpoch 66: val_loss improved from 0.02592 to 0.02400, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9848\nEpoch 67/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\nEpoch 67: val_loss did not improve from 0.02400\n19/19 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9848\nEpoch 68/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\nEpoch 68: val_loss improved from 0.02400 to 0.02149, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9848\nEpoch 69/100\n15/19 [======================>.......] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\nEpoch 69: val_loss did not improve from 0.02149\n19/19 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9848\nEpoch 70/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000    \nEpoch 70: val_loss did not improve from 0.02149\n19/19 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9848\nEpoch 71/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\nEpoch 71: val_loss did not improve from 0.02149\n19/19 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9848\nEpoch 72/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\nEpoch 72: val_loss did not improve from 0.02149\n19/19 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9848\nEpoch 73/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \nEpoch 73: val_loss improved from 0.02149 to 0.02030, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9848\nEpoch 74/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    \nEpoch 74: val_loss improved from 0.02030 to 0.01947, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9848\nEpoch 75/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\nEpoch 75: val_loss improved from 0.01947 to 0.01900, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9848\nEpoch 76/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\nEpoch 76: val_loss improved from 0.01900 to 0.01804, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9848\nEpoch 77/100\n12/19 [=================>............] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \nEpoch 77: val_loss improved from 0.01804 to 0.01770, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9848\nEpoch 78/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\nEpoch 78: val_loss improved from 0.01770 to 0.01678, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9848\nEpoch 79/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\nEpoch 79: val_loss did not improve from 0.01678\n19/19 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9848\nEpoch 80/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\nEpoch 80: val_loss did not improve from 0.01678\n19/19 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9848\nEpoch 81/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\nEpoch 81: val_loss improved from 0.01678 to 0.01606, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9848\nEpoch 82/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \nEpoch 82: val_loss did not improve from 0.01606\n19/19 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9848\nEpoch 83/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\nEpoch 83: val_loss did not improve from 0.01606\n19/19 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9848\nEpoch 84/100\n13/19 [===================>..........] - ETA: 0s - loss: 9.7957e-04 - accuracy: 1.0000\nEpoch 84: val_loss improved from 0.01606 to 0.01600, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9848\nEpoch 85/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\nEpoch 85: val_loss did not improve from 0.01600\n19/19 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9848\nEpoch 86/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\nEpoch 86: val_loss did not improve from 0.01600\n19/19 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9848\nEpoch 87/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \nEpoch 87: val_loss did not improve from 0.01600\n19/19 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9848\nEpoch 88/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \nEpoch 88: val_loss improved from 0.01600 to 0.01531, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9848\nEpoch 89/100\n14/19 [=====================>........] - ETA: 0s - loss: 8.5616e-04 - accuracy: 1.0000\nEpoch 89: val_loss improved from 0.01531 to 0.01523, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9848\nEpoch 90/100\n13/19 [===================>..........] - ETA: 0s - loss: 8.9697e-04 - accuracy: 1.0000\nEpoch 90: val_loss improved from 0.01523 to 0.01509, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9848\nEpoch 91/100\n12/19 [=================>............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\nEpoch 91: val_loss did not improve from 0.01509\n19/19 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9848\nEpoch 92/100\n14/19 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \nEpoch 92: val_loss did not improve from 0.01509\n19/19 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9848\nEpoch 93/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\nEpoch 93: val_loss did not improve from 0.01509\n19/19 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9848\nEpoch 94/100\n10/19 [==============>...............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \nEpoch 94: val_loss did not improve from 0.01509\n19/19 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9848\nEpoch 95/100\n11/19 [================>.............] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \nEpoch 95: val_loss improved from 0.01509 to 0.01504, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9848\nEpoch 96/100\n11/19 [================>.............] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\nEpoch 96: val_loss did not improve from 0.01504\n19/19 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9848\nEpoch 97/100\n19/19 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \nEpoch 97: val_loss did not improve from 0.01504\n19/19 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9848\nEpoch 98/100\n12/19 [=================>............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\nEpoch 98: val_loss did not improve from 0.01504\n19/19 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9848\nEpoch 99/100\n11/19 [================>.............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\nEpoch 99: val_loss did not improve from 0.01504\n19/19 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9848\nEpoch 100/100\n13/19 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \nEpoch 100: val_loss improved from 0.01504 to 0.01484, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 8ms/step - loss: 9.9044e-04 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9848\nTraining completed in time:  0:00:23.179362\n","output_type":"stream"}]},{"cell_type":"code","source":"test_accuracy=model.evaluate(X_test,y_test,verbose=0)\nprint(test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:27.754494Z","iopub.execute_input":"2023-09-17T07:23:27.754969Z","iopub.status.idle":"2023-09-17T07:23:27.848834Z","shell.execute_reply.started":"2023-09-17T07:23:27.754933Z","shell.execute_reply":"2023-09-17T07:23:27.847580Z"},"trusted":true},"execution_count":203,"outputs":[{"name":"stdout","text":"[0.01484384573996067, 0.9848484992980957]\n","output_type":"stream"}]},{"cell_type":"code","source":"#model.predict_classes(X_test)\npredict_x=model.predict(X_test) \nclasses_x=np.argmax(predict_x,axis=1)\nprint(classes_x)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:40.739339Z","iopub.execute_input":"2023-09-17T07:23:40.740473Z","iopub.status.idle":"2023-09-17T07:23:40.846047Z","shell.execute_reply.started":"2023-09-17T07:23:40.740423Z","shell.execute_reply":"2023-09-17T07:23:40.844367Z"},"trusted":true},"execution_count":205,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 0s 4ms/step\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"#print(predict_x)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:40.848394Z","iopub.execute_input":"2023-09-17T07:23:40.848762Z","iopub.status.idle":"2023-09-17T07:23:40.854555Z","shell.execute_reply.started":"2023-09-17T07:23:40.848732Z","shell.execute_reply":"2023-09-17T07:23:40.852941Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:40.856255Z","iopub.execute_input":"2023-09-17T07:23:40.856709Z","iopub.status.idle":"2023-09-17T07:23:40.871689Z","shell.execute_reply.started":"2023-09-17T07:23:40.856674Z","shell.execute_reply":"2023-09-17T07:23:40.870163Z"},"trusted":true},"execution_count":207,"outputs":[{"execution_count":207,"output_type":"execute_result","data":{"text/plain":"(66, 1, 40)"},"metadata":{}}]},{"cell_type":"code","source":"y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:40.876856Z","iopub.execute_input":"2023-09-17T07:23:40.878153Z","iopub.status.idle":"2023-09-17T07:23:40.889170Z","shell.execute_reply.started":"2023-09-17T07:23:40.878088Z","shell.execute_reply":"2023-09-17T07:23:40.887820Z"},"trusted":true},"execution_count":208,"outputs":[{"execution_count":208,"output_type":"execute_result","data":{"text/plain":"(66,)"},"metadata":{}}]},{"cell_type":"code","source":"predict_x.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:40.891990Z","iopub.execute_input":"2023-09-17T07:23:40.892385Z","iopub.status.idle":"2023-09-17T07:23:40.904134Z","shell.execute_reply.started":"2023-09-17T07:23:40.892352Z","shell.execute_reply":"2023-09-17T07:23:40.902890Z"},"trusted":true},"execution_count":209,"outputs":[{"execution_count":209,"output_type":"execute_result","data":{"text/plain":"(66, 1)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, classes_x)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T07:23:40.905337Z","iopub.execute_input":"2023-09-17T07:23:40.906100Z","iopub.status.idle":"2023-09-17T07:23:40.921662Z","shell.execute_reply.started":"2023-09-17T07:23:40.906056Z","shell.execute_reply":"2023-09-17T07:23:40.920314Z"},"trusted":true},"execution_count":210,"outputs":[{"execution_count":210,"output_type":"execute_result","data":{"text/plain":"0.3484848484848485"},"metadata":{}}]}]}