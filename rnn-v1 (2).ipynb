{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra.\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv).\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-17T11:59:07.590369Z","iopub.execute_input":"2023-09-17T11:59:07.590857Z","iopub.status.idle":"2023-09-17T11:59:08.105939Z","shell.execute_reply.started":"2023-09-17T11:59:07.590818Z","shell.execute_reply":"2023-09-17T11:59:08.105046Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Loading metadata input.\nmetal_excel_dir = \"../input/audio-based-violence-detection-dataset/VSD.xlsx\"\nmetadata = pd.read_excel(metal_excel_dir,sheet_name='read_dataset')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T11:59:08.107585Z","iopub.execute_input":"2023-09-17T11:59:08.108210Z","iopub.status.idle":"2023-09-17T11:59:08.600923Z","shell.execute_reply.started":"2023-09-17T11:59:08.108180Z","shell.execute_reply":"2023-09-17T11:59:08.599856Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Cleaning metadata input.\nmetadata = metadata.drop(metadata[metadata['File_segment_name'] == \"NaN\"].index)\nmetadata.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-17T11:59:08.602315Z","iopub.execute_input":"2023-09-17T11:59:08.603278Z","iopub.status.idle":"2023-09-17T11:59:08.619346Z","shell.execute_reply.started":"2023-09-17T11:59:08.603246Z","shell.execute_reply":"2023-09-17T11:59:08.618425Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(341, 5)"},"metadata":{}}]},{"cell_type":"code","source":"metadata.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T11:59:08.621968Z","iopub.execute_input":"2023-09-17T11:59:08.623063Z","iopub.status.idle":"2023-09-17T11:59:08.645746Z","shell.execute_reply.started":"2023-09-17T11:59:08.623029Z","shell.execute_reply":"2023-09-17T11:59:08.644463Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  File_segment_name  Duration  Violence_start  Violence_end  Violence_duration\n0         angry_011     117.0            21.0        38.000              17.00\n1         angry_011     117.0            40.0        55.000              15.00\n2         angry_011     117.0            60.0        79.000              19.00\n3         angry_011     117.0            85.0        95.000              10.00\n4         angry_011     117.0           101.0       110.000               9.00\n5         angry_012      32.0             0.0         0.020               0.02\n6         angry_013      72.0             0.0         0.010               0.00\n7         angry_014      50.0             0.0         0.012               0.00\n8         angry_015     162.0            64.0        71.000               7.00\n9         angry_015     162.0            89.0       100.000              11.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File_segment_name</th>\n      <th>Duration</th>\n      <th>Violence_start</th>\n      <th>Violence_end</th>\n      <th>Violence_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>angry_011</td>\n      <td>117.0</td>\n      <td>21.0</td>\n      <td>38.000</td>\n      <td>17.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>angry_011</td>\n      <td>117.0</td>\n      <td>40.0</td>\n      <td>55.000</td>\n      <td>15.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>angry_011</td>\n      <td>117.0</td>\n      <td>60.0</td>\n      <td>79.000</td>\n      <td>19.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>angry_011</td>\n      <td>117.0</td>\n      <td>85.0</td>\n      <td>95.000</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>angry_011</td>\n      <td>117.0</td>\n      <td>101.0</td>\n      <td>110.000</td>\n      <td>9.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>angry_012</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>0.020</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>angry_013</td>\n      <td>72.0</td>\n      <td>0.0</td>\n      <td>0.010</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>angry_014</td>\n      <td>50.0</td>\n      <td>0.0</td>\n      <td>0.012</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>angry_015</td>\n      <td>162.0</td>\n      <td>64.0</td>\n      <td>71.000</td>\n      <td>7.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>angry_015</td>\n      <td>162.0</td>\n      <td>89.0</td>\n      <td>100.000</td>\n      <td>11.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Creating directory paths to store violence and non-violence data.\nviolence_dir = \"../violence_data\"\nnon_violence_dir = \"../non_violence_data\"","metadata":{"execution":{"iopub.status.busy":"2023-09-17T11:59:08.647386Z","iopub.execute_input":"2023-09-17T11:59:08.647788Z","iopub.status.idle":"2023-09-17T11:59:08.653636Z","shell.execute_reply.started":"2023-09-17T11:59:08.647749Z","shell.execute_reply":"2023-09-17T11:59:08.652354Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Creating Directories.\nos.mkdir(violence_dir)\nos.mkdir(non_violence_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T11:59:08.655169Z","iopub.execute_input":"2023-09-17T11:59:08.656210Z","iopub.status.idle":"2023-09-17T11:59:08.662154Z","shell.execute_reply.started":"2023-09-17T11:59:08.656171Z","shell.execute_reply":"2023-09-17T11:59:08.661256Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# We have segments of audio in our data, Hence importing pydub to process segments.\nfrom pydub import AudioSegment\n\n# Looping over all the records in metadata input.\nfor record in metadata.values:\n    t1 = 1000 * record[2]\n    t2 = 1000 * record[3]\n    audio  = AudioSegment.from_wav(os.path.join(\"../input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD\", str(record[0]) + \".wav\"))\n    violence_segment = audio[t1:t2]\n    # Storing the violence audio segment in the corresponding directory.\n    violence_segment.export(os.path.join(violence_dir,record[0]+\".wav\"))\n    \nprint(\"===== Violent audio segments separated =====\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T11:59:08.663437Z","iopub.execute_input":"2023-09-17T11:59:08.664416Z","iopub.status.idle":"2023-09-17T12:01:44.131636Z","shell.execute_reply.started":"2023-09-17T11:59:08.664377Z","shell.execute_reply":"2023-09-17T12:01:44.130309Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"===== Violent audio segments separated =====\n","output_type":"stream"}]},{"cell_type":"code","source":"for record in metadata.values:\n    t1 = 1000 * record[2]\n    t2 = 1000 * record[3]\n    audio  = AudioSegment.from_wav(os.path.join(\"../input/audio-based-violence-detection-dataset/audios_VSD/audios_VSD\", str(record[0]) + \".wav\"))\n    non_violence_segment = audio[0:t1]\n    non_violence_segment.export(os.path.join(non_violence_dir,record[0]+\"_non_violence.wav\"))\n\nprint(\"===== Non-violent audio segments separated =====\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:01:44.133489Z","iopub.execute_input":"2023-09-17T12:01:44.134997Z","iopub.status.idle":"2023-09-17T12:09:47.882755Z","shell.execute_reply.started":"2023-09-17T12:01:44.134945Z","shell.execute_reply":"2023-09-17T12:09:47.881444Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"===== Non-violent audio segments separated =====\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing Librosa to extract audio features.\nimport librosa\n\n# Function to extract MFCC (Mel Frequency Cepstral Coefficients) from the audio sample.\ndef features_extractor(file):\n    audio, sample_rate = librosa.load(file) \n    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n    # We do mean of transpose of value to find out scaled feature.\n    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n    return mfccs_scaled_features","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:09:47.884653Z","iopub.execute_input":"2023-09-17T12:09:47.885056Z","iopub.status.idle":"2023-09-17T12:09:47.901412Z","shell.execute_reply.started":"2023-09-17T12:09:47.885015Z","shell.execute_reply":"2023-09-17T12:09:47.900281Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Creating empty list to store the extracted features.\nextracted_features=[]\n\n# Loop to process violent data extraction process.\nfor record in metadata.values:\n    file_name = os.path.join(os.path.abspath(violence_dir), record[0] + \".wav\")\n    # Labelling violent audio as 1.\n    final_class_labels = 1 \n    try:\n        data = features_extractor(file_name)\n    except:\n        continue\n    extracted_features.append([data,final_class_labels])\nprint(\"===== Successfully extracted violent audio data =====\")\n\n# Loop to process non-violent data extraction process.\nfor record in metadata.values:\n    file_name = os.path.join(os.path.abspath(non_violence_dir),record[0]+\"_non_violence.wav\")\n    # Labelling non-violent audio as 0.\n    final_class_labels = 0\n    try:\n        data = features_extractor(file_name)\n    except:\n        continue\n    extracted_features.append([data,final_class_labels])\nprint(\"===== Successfully extracted non-violent audio data =====\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:09:47.906683Z","iopub.execute_input":"2023-09-17T12:09:47.907078Z","iopub.status.idle":"2023-09-17T12:13:38.620429Z","shell.execute_reply.started":"2023-09-17T12:09:47.907045Z","shell.execute_reply":"2023-09-17T12:13:38.619268Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"===== Successfully extracted violent audio data =====\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"},{"name":"stdout","text":"===== Successfully extracted non-violent audio data =====\n","output_type":"stream"},{"name":"stderr","text":"[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Converting extracted_features to Pandas dataframe.\nextracted_features_df = pd.DataFrame(extracted_features,columns=['feature','class'])\nextracted_features_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:38.622111Z","iopub.execute_input":"2023-09-17T12:13:38.622752Z","iopub.status.idle":"2023-09-17T12:13:38.641485Z","shell.execute_reply.started":"2023-09-17T12:13:38.622717Z","shell.execute_reply":"2023-09-17T12:13:38.640292Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             feature  class\n0  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n1  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n2  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n3  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1\n4  [-136.46625, 114.69909, -33.55017, 21.952213, ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-136.46625, 114.69909, -33.55017, 21.952213, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Checking Value counts.\nextracted_features_df[\"class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:38.643124Z","iopub.execute_input":"2023-09-17T12:13:38.643546Z","iopub.status.idle":"2023-09-17T12:13:38.662956Z","shell.execute_reply.started":"2023-09-17T12:13:38.643514Z","shell.execute_reply":"2023-09-17T12:13:38.661637Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"class\n1    341\n0    315\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Split the dataset into independent and dependent dataset.\nX = np.array(extracted_features_df[\"feature\"].tolist())\ny = np.array(extracted_features_df[\"class\"].tolist())\n\n# Train Test Split.\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:38.664529Z","iopub.execute_input":"2023-09-17T12:13:38.665562Z","iopub.status.idle":"2023-09-17T12:13:38.855562Z","shell.execute_reply.started":"2023-09-17T12:13:38.665515Z","shell.execute_reply":"2023-09-17T12:13:38.854229Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:38.857641Z","iopub.execute_input":"2023-09-17T12:13:38.858035Z","iopub.status.idle":"2023-09-17T12:13:38.863442Z","shell.execute_reply.started":"2023-09-17T12:13:38.858002Z","shell.execute_reply":"2023-09-17T12:13:38.862319Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(590, 40) (66, 40)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reshaping to make the datasets compatible with LSTM.\nX_train=X_train.reshape(590,1,40)\nX_test=X_test.reshape(66,1, 40)\nprint(X_train.shape, X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:38.865406Z","iopub.execute_input":"2023-09-17T12:13:38.865751Z","iopub.status.idle":"2023-09-17T12:13:38.880136Z","shell.execute_reply.started":"2023-09-17T12:13:38.865721Z","shell.execute_reply":"2023-09-17T12:13:38.879192Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(590, 1, 40) (66, 1, 40)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,SimpleRNN, LSTM\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn import metrics\n\n# No of classes.\nnum_labels=y.shape[0]\nmodel=Sequential()\nmodel.add(LSTM(64,input_shape=(1,40)))\n\n### 1st layer.\nmodel.add(Dense(32))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n### 2nd layer.\n#model.add(Dense(128))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.4))\n\n### 3rd layer.\n#model.add(Dense(64))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n### 4th layer.\n#model.add(Dense(32))\n#model.add(Activation('relu'))\n\n### 5th layer.\n#model.add(Dense(16))\n#model.add(Activation('relu'))\n\n### 6th layer.\n#model.add(Dense(8))\n#model.add(Activation('relu'))\n\n### Final layer.\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:38.881509Z","iopub.execute_input":"2023-09-17T12:13:38.882316Z","iopub.status.idle":"2023-09-17T12:13:48.684719Z","shell.execute_reply.started":"2023-09-17T12:13:38.882282Z","shell.execute_reply":"2023-09-17T12:13:48.683656Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:48.686275Z","iopub.execute_input":"2023-09-17T12:13:48.686851Z","iopub.status.idle":"2023-09-17T12:13:48.713999Z","shell.execute_reply.started":"2023-09-17T12:13:48.686810Z","shell.execute_reply":"2023-09-17T12:13:48.712727Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 64)                26880     \n                                                                 \n dense (Dense)               (None, 32)                2080      \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n activation (Activation)     (None, 1)                 0         \n                                                                 \n=================================================================\nTotal params: 28,993\nTrainable params: 28,993\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model Compilation.\nmodel.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:48.715520Z","iopub.execute_input":"2023-09-17T12:13:48.715889Z","iopub.status.idle":"2023-09-17T12:13:48.739515Z","shell.execute_reply.started":"2023-09-17T12:13:48.715845Z","shell.execute_reply":"2023-09-17T12:13:48.738361Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Trianing model.\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom datetime import datetime \nnum_epochs = 10\nnum_batch_size = 32\ncheckpointer = ModelCheckpoint(filepath='./audio_classification.hdf5', verbose=1, save_best_only=True)\nstart = datetime.now()\nmodel.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\nduration = datetime.now() - start\nprint(\"Training completed in time:\", duration)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:48.741948Z","iopub.execute_input":"2023-09-17T12:13:48.742319Z","iopub.status.idle":"2023-09-17T12:13:54.015628Z","shell.execute_reply.started":"2023-09-17T12:13:48.742288Z","shell.execute_reply":"2023-09-17T12:13:54.014398Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/10\n17/19 [=========================>....] - ETA: 0s - loss: 0.6896 - accuracy: 0.5129 \nEpoch 1: val_loss improved from inf to 0.65128, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 4s 44ms/step - loss: 0.6868 - accuracy: 0.5271 - val_loss: 0.6513 - val_accuracy: 0.5909\nEpoch 2/10\n15/19 [======================>.......] - ETA: 0s - loss: 0.5926 - accuracy: 0.7250\nEpoch 2: val_loss improved from 0.65128 to 0.57414, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.5926 - accuracy: 0.7169 - val_loss: 0.5741 - val_accuracy: 0.6364\nEpoch 3/10\n16/19 [========================>.....] - ETA: 0s - loss: 0.5131 - accuracy: 0.7520\nEpoch 3: val_loss improved from 0.57414 to 0.53754, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.7441 - val_loss: 0.5375 - val_accuracy: 0.6212\nEpoch 4/10\n18/19 [===========================>..] - ETA: 0s - loss: 0.4534 - accuracy: 0.7847\nEpoch 4: val_loss improved from 0.53754 to 0.46923, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.4692 - val_accuracy: 0.7121\nEpoch 5/10\n17/19 [=========================>....] - ETA: 0s - loss: 0.4077 - accuracy: 0.8235\nEpoch 5: val_loss improved from 0.46923 to 0.44911, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8254 - val_loss: 0.4491 - val_accuracy: 0.7121\nEpoch 6/10\n15/19 [======================>.......] - ETA: 0s - loss: 0.3696 - accuracy: 0.8708\nEpoch 6: val_loss improved from 0.44911 to 0.43073, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8678 - val_loss: 0.4307 - val_accuracy: 0.7879\nEpoch 7/10\n16/19 [========================>.....] - ETA: 0s - loss: 0.3208 - accuracy: 0.8926\nEpoch 7: val_loss improved from 0.43073 to 0.39983, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.3237 - accuracy: 0.8949 - val_loss: 0.3998 - val_accuracy: 0.7879\nEpoch 8/10\n16/19 [========================>.....] - ETA: 0s - loss: 0.2791 - accuracy: 0.9180\nEpoch 8: val_loss improved from 0.39983 to 0.35933, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.2802 - accuracy: 0.9169 - val_loss: 0.3593 - val_accuracy: 0.8333\nEpoch 9/10\n15/19 [======================>.......] - ETA: 0s - loss: 0.2410 - accuracy: 0.9250\nEpoch 9: val_loss improved from 0.35933 to 0.30866, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.9237 - val_loss: 0.3087 - val_accuracy: 0.8485\nEpoch 10/10\n15/19 [======================>.......] - ETA: 0s - loss: 0.2095 - accuracy: 0.9333\nEpoch 10: val_loss improved from 0.30866 to 0.30542, saving model to ./audio_classification.hdf5\n19/19 [==============================] - 0s 7ms/step - loss: 0.2112 - accuracy: 0.9305 - val_loss: 0.3054 - val_accuracy: 0.8636\nTraining completed in time: 0:00:05.264649\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the model on testing data.\ntest_accuracy = model.evaluate(X_test,y_test,verbose=0)\nprint(\"Test accuracy of the model:\", test_accuracy[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:54.017693Z","iopub.execute_input":"2023-09-17T12:13:54.018523Z","iopub.status.idle":"2023-09-17T12:13:54.105174Z","shell.execute_reply.started":"2023-09-17T12:13:54.018477Z","shell.execute_reply":"2023-09-17T12:13:54.103965Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Test accuracy of the model: 0.8636363744735718\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the model on training data.\ntrain_accuracy = model.evaluate(X_train,y_train,verbose=0)\nprint(\"Train accuracy of the model:\", train_accuracy[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:13:54.106424Z","iopub.execute_input":"2023-09-17T12:13:54.106742Z","iopub.status.idle":"2023-09-17T12:13:54.220858Z","shell.execute_reply.started":"2023-09-17T12:13:54.106715Z","shell.execute_reply":"2023-09-17T12:13:54.219713Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Train accuracy of the model: 0.9440677762031555\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prediction on test data.\npredict_x = model.predict(X_test)\nprint(predict_x)\n#classes_x = np.argmax(predict_x,axis=1)\n#print(classes_x)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:15:16.248498Z","iopub.execute_input":"2023-09-17T12:15:16.249008Z","iopub.status.idle":"2023-09-17T12:15:16.342834Z","shell.execute_reply.started":"2023-09-17T12:15:16.248970Z","shell.execute_reply":"2023-09-17T12:15:16.341447Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 0s 3ms/step\n[[0.9421848 ]\n [0.99350417]\n [0.5448032 ]\n [0.17477724]\n [0.10112327]\n [0.86577976]\n [0.46076092]\n [0.99350417]\n [0.6018717 ]\n [0.7599562 ]\n [0.95611954]\n [0.9891732 ]\n [0.20170519]\n [0.03494135]\n [0.45399684]\n [0.00870805]\n [0.17930932]\n [0.45399684]\n [0.12646396]\n [0.7599562 ]\n [0.4192578 ]\n [0.38130635]\n [0.29285124]\n [0.08705474]\n [0.06707651]\n [0.01746246]\n [0.8780639 ]\n [0.06707651]\n [0.15797989]\n [0.98899037]\n [0.99726665]\n [0.96849877]\n [0.95611954]\n [0.83749014]\n [0.99726665]\n [0.95086807]\n [0.08705474]\n [0.2523387 ]\n [0.8235343 ]\n [0.9891732 ]\n [0.17477724]\n [0.24072577]\n [0.78124034]\n [0.7599562 ]\n [0.1367127 ]\n [0.19020621]\n [0.23360994]\n [0.6549962 ]\n [0.981853  ]\n [0.913608  ]\n [0.19091396]\n [0.5341393 ]\n [0.00870805]\n [0.9753863 ]\n [0.9943231 ]\n [0.23018786]\n [0.8151447 ]\n [0.8452584 ]\n [0.38130635]\n [0.12646396]\n [0.99991333]\n [0.9977903 ]\n [0.99991333]\n [0.3721704 ]\n [0.9508681 ]\n [0.12646404]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Saving the model.\nmodel.save(\"model_LSTM_v1.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T12:15:16.344860Z","iopub.execute_input":"2023-09-17T12:15:16.345290Z","iopub.status.idle":"2023-09-17T12:15:16.376693Z","shell.execute_reply.started":"2023-09-17T12:15:16.345255Z","shell.execute_reply":"2023-09-17T12:15:16.375490Z"},"trusted":true},"execution_count":25,"outputs":[]}]}